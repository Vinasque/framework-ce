diff --git a/README.md b/README.md
index 4040792..46f32fa 100644
--- a/README.md
+++ b/README.md
@@ -55,29 +55,164 @@ g++ -std=c++17 main.cpp sqlite3.o -o exes/main
 \exes\main.exe
 ```
 
-## Estrutura do Projeto
+---
+---
+
+# GRPC - A2
+
+Na solução inicial, a comunicação entre o simulador das fontes de dados e o pipeline ETL era feita por meio de arquivos intermediários (CSVs, Json, etc.), onde os dados eram gerados por scripts Python em arquivos CSV/JSON, que eram lidos e processados pelo ETL posteriormente. A abordagem limitava a execução a um único computador e introduzia latências relacionadas à escrita e leitura de disco, que é bem mais lenta que apenas passar os dados diretamente após serem "criados". Essa entregra permite que, através de um mecanismo de comunicação via gRPC, o que permite uma simulaçao de cargas reais distribuídas em rede de forma mais realista, facilita a expansão para o uso de múltiplas máquinas simultaneamente e menor latência, já que não depende mais da criação de arquivos no disco.
+
+## Pré-requisitos
+
+- **gRPC e Protobuf**: você deve ter o [gRPC](https://grpc.io/) e o `protoc` (instalador do Protocol Buffers) disponíveis no seu sistema.  
+- **C++17**: compilador compatível (gcc ou clang).  
+- **Python 3.8+**: para o cliente e geração de stubs Python.  
+
+## Instalação
+
+Para rodar o código em uma máquina Windows, foi-se utilizado do WSL (Windows Subsystem for Linux), já que o gRPC em C++ depende de várias bibliotecas e ferramentas que possuem suporte limitado ou apresentam instabilidades no ambiente Windows tradicional. 
+
+### 1. Windows (via WSL)
+
+Se você não estiver em Linux (se estiver, pode ignorar esse passo), instale o WSL e Ubuntu 22.04:
+
+```bash
+wsl --install
+wsl --install -d Ubuntu-22.04
 ```
-framework-ce/
-├── dashboard/                  # Pasta do dashboard
-│   ├── main.py                 # Executável principal do dashboard
-│   └── requirements.txt        # Bibliotecas necessárias
 
-├── databases/                  # Contém os dados armazenados em .db
-│   └── Database.db             # Banco SQLite principal
+### 2. Dependências do Sistema e Protocol Buffers (protoc)
+
+Após baixar o WSL, reinicie o seu PC e instale as dependências abaixo (já dentro do CMD do WSL, e não no CMD comum Windows):
+
+```bash
+# Dependências do Linux que serão necessárias para fazer o código rodar, como o sqlite, python, cmake, etc.
+sudo apt update
+sudo apt install -y \
+  build-essential autoconf libtool pkg-config cmake git curl unzip \
+  libgrpc++-dev libc-ares-dev libre2-dev libabsl-dev libabsl-synchronization-dev \
+  libssl-dev sqlite3 libsqlite3-dev python3 python3-pip
 
-├── generator/                  # Dados mocks e arquivos que os geram
-│   ├── flights.csv             
-│   ├── orders.json             
-│   ├── users.csv               
-│   └── flight_generator.py
-│   ...
+# Protocol Buffers, usado para serializar dados, será utilizado no projeto
+PROTOC_ZIP=protoc-21.12-linux-x86_64.zip
+curl -OL https://github.com/protocolbuffers/protobuf/releases/download/v21.12/$PROTOC_ZIP
+sudo unzip -o $PROTOC_ZIP -d /usr/local bin/protoc
+sudo unzip -o $PROTOC_ZIP -d /usr/local 'include/*'
+rm -f $PROTOC_ZIP
+```
 
-├── src/                        # Código fonte principal
-│   Contém os handlers, estruturas do extrator, loader, threads, pipeline principal, etc
-│   └── main.cpp                # Main a ser executada
+### 3.1. gRPC em C++
 
-├── tests/                      # Testes feitos no decorrer do projeto
+```bash
+git clone --recurse-submodules -b v1.56.0 https://github.com/grpc/grpc
+cd grpc
+mkdir -p cmake/build && cd cmake/build
+cmake ../..
+make -j$(nproc)
+sudo make install
+sudo ldconfig
+```
+
+### 3.2. gRPC em Python
+
+```bash
+sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 1
+python -m venv ~/grpc-env
+source ~/grpc-env/bin/activate
+pip install grpcio grpcio-tools protobuf
+```
 
-├── README.md                   # Documentação do projeto
-├── Relatório.pdf               # Relatório 
+## Geração de Código & Build
+
+### Servidor C++ (stubs e compilação) e como Executar
+
+Dentro da pasta do projeto, gere os exes através do ```make```, que você deve rodar dentro da pasta ```src```, que contem o Makefile, que contém instruções sobre como construir e compilar o projeto, onde o ```make``` automatiza o processo de compilação.
+
+```bash
+protoc --grpc_out=. --plugin=protoc-gen-grpc=$(which grpc_cpp_plugin) event.proto
+protoc --cpp_out=. event.proto
+
+cd .\src\
+make        # gera executáveis em ./exes
+./exes/server.exe
+./exes/etl.exe
+```
+
+### Cliente Python (stubs) e como Executar
+
+Para rodar os clientes, o código dos clientes está disponível na pasta ```grpc```, onde temos o código ```cliente.py```, que gera os dados que serão enviados para o ETL pelo python e envia ao servidor em C++, que já foi aberto.
+
+```bash
+cd grpc
+python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. event.proto
+
+# Execução dentro da pasta grpc
+python grpc/cliente.py <num_eventos> <intervalo_ms>  # roda os clientes
+```
+
+## Execução e Resultados
+
+Ao rodar ambos os arquivos, você deve obter um resultado como esse, onde os terminais conseguem trocar mensagens:
+
+![image](https://github.com/user-attachments/assets/259cd87c-3c47-426e-8d4d-19c58182fcd6)
+
+Os resultados de forma mais detalhada estão disponíveis no relatório ```gRPC.pdf``` disponível neste repositório do GitHub.
+
+
+## Estrutura do Projeto
+```
+framework-ce/
+├── dashboard/
+│ ├── main.py              # Executável principal do dashboard
+│ └── requirements.txt     # Bibliotecas necessárias
+│
+├── databases/
+│ └── Database.db          # Banco SQLite principal
+│
+├── generator/             # Onde os dados eram gerados (antes de começarmos a usar gRPC)
+│ ├── flights.csv
+│ ├── orders.json
+│ ├── users.csv
+│ └── flight_generator.py
+│ ...
+│
+├── grpc/
+│ ├── pycache/ 
+│ ├── client.py             # Cliente que envia eventos via gRPC
+│ ├── event.proto           # Definição dos eventos (Protobuf)
+│ ├── event_pb2.py          # Código gerado do .proto (Python)
+│ ├── event_pb2_grpc.py     # Código gRPC gerado (Python)
+│ ├── event.pb.cc           # Código gerado do .proto (C++)
+│ ├── event.pb.h            
+│ ├── event.pb.o            # Objeto compilado (C++)
+│ ├── event.grpc.pb.cc      # Código gRPC gerado (C++)
+│ ├── event.grpc.pb.h       
+│ └── event.grpc.pb.o       # Objeto compilado (C++)
+│
+├── src/
+│ ├── exes/                 # Executáveis gerados (ex: server.exe)
+│ ├── dataAdder.cpp         # Componente auxiliar de dados
+│ ├── database.h            # Definições do banco SQLite
+│ ├── dataframe.hpp
+│ ├── extractor.hpp
+│ ├── handler.hpp
+│ ├── json.hpp
+│ ├── loader.hpp
+│ ├── main.cpp              # Entrada principal
+│ ├── main2.cpp             # Variante de execução (debug/teste)
+│ ├── Makefile              # Script de build principal
+│ ├── queue.hpp
+│ ├── series.hpp
+│ ├── server.cpp            # Servidor gRPC que recebe os eventos
+│ ├── server.o              # Objeto compilado
+│ ├── sqlite3.o             # Objeto SQLite
+│ ├── test.cpp            
+│ ├── threadPool.hpp        # Gerenciamento de threads
+│ └── trigger.hpp           # Lógica de triggers/ativadores
+│
+├── tests/                  # Testes do projeto
+│
+├── README.md               # Este arquivo
+├── gRPC.pdf                # Relatório da Entrega 1 da A2
+└── Relatório.pdf           # Relatório final da A1
 ```
diff --git "a/Relat\303\263rio.pdf" "b/Relat\303\263rio.pdf"
deleted file mode 100644
index 00207fc..0000000
--- "a/Relat\303\263rio.pdf"
+++ /dev/null
@@ -1,337 +0,0 @@
-                               Funda¸ca˜o Getu´lio Vargas
-                     EMAp - Escola de Matem´atica Aplicada
-                     Ciˆencia de Dados e Inteligˆencia Artificial
-
-                                 Computa¸ca˜o Escal´avel
-
-        MICRO-FRAMEWORK:
-VENDA DE PASSAGENS AE´REAS
-
-                                     Guilherme Buss
-                                  Guilherme Carvalho
-
-                                     Gustavo Bianchi
-                                       Joa˜o Gabriel
-
-                                  Vin´ıcius Nascimento
-
-                                      Rio de Janeiro
-                                            2025
-Sum´ario
-
-1 Motiva¸c˜ao                       2
-
-2 Arquitetura Geral                 2
-
-2.1 M´odulos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
-
-2.2 Pipeline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
-
-2.2.1 Extra¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
-
-2.2.2 Transforma¸c˜ao . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
-
-2.2.3 Agrega¸c˜ao e Carregamento . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
-
-3 Problemas e Solu¸co˜es            3
-
-3.1 Carregamento Repetido de Dados Auxiliares . . . . . . . . . . . . . . . . . . . . . . 3
-
-3.2 Condi¸c˜oes de Corrida na Impressa˜o de Resultados . . . . . . . . . . . . . . . . . . 4
-
-3.3 Satura¸c˜ao do SQLite com Mu´ltiplas Conex˜oes . . . . . . . . . . . . . . . . . . . . . 4
-
-3.4 Gargalo na Agregac¸˜ao Final . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
-
-3.5 Falta de Flexibilidade na Extra¸c˜ao de Esquemas . . . . . . . . . . . . . . . . . . . 4
-
-3.6 Parada Lenta do TimerTrigger . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
-
-4 Estrat´egias de Processamento     4
-
-4.1 Pipeline Sequencial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
-
-4.2 Pipeline Paralelo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
-
-5 Triggers                          5
-
-6 Benchmarking                      5
-
-7 Resultados                        5
-
-7.1 Tempo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
-
-7.2 Estat´ısticas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
-
-                                 1
-1 Motiva¸c˜ao
-
-O objetivo deste projeto ´e desenvolver um micro framework em C++ voltado para a extra¸c˜ao,
-processamento, transforma¸ca˜o e carregamento (ETL) de dados de vendas de passagens a´ereas.
-Como forma de otimiza¸c˜ao do nosso sistema, ele realiza benchmarks comparando o desempenho
-entre pipelines sequenciais e paralelos com diferentes quantidades de threads, mostrando a eficiˆencia
-no uso destas.
-
-2 Arquitetura Geral
-
-2.1 M´odulos
-
-O sistema foi dividido em mo´dulos/componentes:
-
-Componente  Responsabilidade Principal
-DataFrame   Representa¸ca˜o tabular dos dados em mem´oria
-Database    Interface para criac¸a˜o e manipula¸c˜ao de tabelas no SQLite
-Extractor   Extra¸c˜ao de dados de arquivos JSON e CSV
-Handler     Processamento e transformac¸˜ao de dados (validac¸˜ao, filtros, etc.)
-Loader      Carga dos dados processados no banco SQLite
-Queue       Comunica¸ca˜o thread-safe entre fases da pipeline paralela
-Series      Representa¸ca˜o unidimensional de dados com opera¸co˜es aritm´eticas e transforma¸c˜oes
-ThreadPool  Execu¸c˜ao paralela com mu´ltiplas threads
-Trigger     Disparo de processamento com base em tempo ou requisic¸˜ao externa
-
-2.2 Pipeline
-
-O pipeline ´e composto por mu´ltiplos componentes conectados em s´erie e em paralelo, organizados
-em trˆes grandes etapas: extrac¸a˜o, transformac¸a˜o e carregamento.
-
-         Figura 1: Arquitetura geral do pipeline de processamento e integrac¸˜ao com SQLite
-
-2.2.1 Extra¸c˜ao
-Os dados brutos s˜ao extra´ıdos de diferentes fontes:
-
-    • JSON com assento: cont´em os dados das transa¸c˜oes de venda de passagens. E´ processado
-       pelo componente JsonExtractor.
-
-                                                               2
-    • CSV flights.csv: informa¸c˜oes sobre os voos, extra´ıdas por um CSVExtractor.
-    • CSV users.csv: cont´em dados de usua´rios, como pa´ıs de origem.
-    • CSV flights seats.csv: cont´em informa¸co˜es sobre os assentos de voos e seus tipos.
-
-2.2.2 Transforma¸c˜ao
-Ap´os a extra¸c˜ao, os dados passam por uma s´erie de Handlers que compo˜em o nu´cleo do pro-
-cessamento l´ogico do sistema. Esses m´odulos operam de forma encadeada e paralela, aplicando
-valida¸c˜oes, filtros, enriquecimento e agregac¸˜oes:
-
-    • Validation Handler: verifica se os dados extra´ıdos do JSON est˜ao va´lidos para o proces-
-       samento.
-
-    • StatusFilter Handler: filtra os dados com base no status da transa¸ca˜o.
-    • Date Handler: normaliza ou filtra os dados por data da transac¸˜ao.
-    • FlightInfoEnricher Handler: enriquece os dados com informa¸co˜es dos voos, tamb´em cal-
-
-       culando estat´ısticas relacionadas.
-    • DestinationCounter Handler: conta a quantidade de viagens por destino.
-    • UsersCountryRevenue Handler: correlaciona usua´rios com receitas por pa´ıs, utilizando
-
-       os dados do users.csv.
-    • SeatTypeRevenue Handler: associa os tipos de assento a` receita gerada, utilizando
-
-       flights seats.csv.
-    • Revenue Handler: calcula a receita total por venda.
-    • CardRevenue Handler: calcula a receita total por tipo de carta˜o.
-
-2.2.3 Agrega¸c˜ao e Carregamento
-Apo´s o processamento e agrega¸ca˜o dos dados, os resultados s˜ao encaminhados aos componentes
-Loader, responsa´veis por inserir os dados transformados no banco de dados SQLite.
-A arquitetura modular, com execu¸c˜ao paralela dos fluxos, promove desempenho e escalabilidade.
-O modelo ´e extens´ıvel, permitindo a adic¸˜ao de novos Handlers, fontes de dados e l´ogicas de
-transforma¸ca˜o conforme necessa´rio.
-
-3 Problemas e Solu¸co˜es
-
-Nesta se¸c˜ao descrevemos os principais desafios enfrentados durante o desenvolvimento da main.cpp
-e as solu¸co˜es implementadas para garantir a robustez, performance e escalabilidade do micro-
-framework.
-
-3.1 Carregamento Repetido de Dados Auxiliares
-
-Problema: Cada execuc¸a˜o de processSequentialChunk e processParallelChunk realizava a
-leitura de users.csv, flights seats.csv e flights.csv, resultando em excesso de I/O e pro-
-cessamento desnecess´ario.
-Solu¸c˜ao:
-
- • Carregar os DataFrames uma u´nica vez no in´ıcio do programa.
- • Compartilhar os ponteiros usando std::shared ptr, evitando c´opias.
- • Construir mapas auxiliares (userIdToCountry, seatKeyToClass) fora do la¸co de execu¸ca˜o
-
-    paralela.
-
-                                                               3
-3.2 Condic¸˜oes de Corrida na Impress˜ao de Resultados
-
-Problema: A sa´ıda das threads no console ficava embaralhada, dificultando a leitura da tabela.
-Solu¸c˜ao:
- • Utiliza¸ca˜o de um std::mutex table mutex global.
- • Prote¸c˜ao das fun¸co˜es printTableHeader() e printTableRow() com std::lock guard<std::mutex>.
-
-3.3 Satura¸c˜ao do SQLite com Mu´ltiplas Conex˜oes
-
-Problema: Gravac¸o˜es simultaˆneas no mesmo banco SQLite causavam conten¸c˜ao e lentid˜ao.
-Solu¸c˜ao:
- • Criar tabelas separadas para cada configura¸c˜ao de pipeline (ex.: 4, 8, 12).
- • Considerar o uso de batch inserts ou migra¸c˜ao futura para um SGBD com melhor suporte `a
-
-    concorrˆencia (ex.: PostgreSQL).
-
-3.4 Gargalo na Agrega¸c˜ao Final
-
-Problema: A agregac¸a˜o dos resultados parciais ocorria de forma sequencial, tornando-se um
-gargalo de desempenho.
-Solu¸c˜ao:
-
- • Utilizar filas tipadas (Queue<...>) para segmentar os resultados.
- • Concatenar os lotes antes de aplicar operac¸o˜es como groupby(), reduzindo o nu´mero de varre-
-
-    duras nos dados.
-
-3.5 Falta de Flexibilidade na Extrac¸˜ao de Esquemas
-
-Problema: O extrator JSON possu´ıa um esquema fixo, o que dificultava o reuso com diferentes
-estruturas de dados.
-Solu¸c˜ao:
-
- • Permitir que o Extractor aceite um std::vector<std::string> com os nomes das colunas.
- • Generalizar os m´etodos extractChunk(...) e extractRandomChunk(...) com parˆametros de
-
-    esquema e tamanho.
-
-3.6 Parada Lenta do TimerTrigger
-
-Problema: Ao chamar stop(), o TimerTrigger aguardava o t´ermino do sleep for(), atrasando
-a finaliza¸c˜ao.
-Solu¸c˜ao:
-
- • Tornar a flag running uma vari´avel atˆomica (std::atomic<bool>).
- • Ao encerrar, definir running = false e chamar timerThread.join() para finalizar imediata-
-
-    mente ap´os o intervalo atual.
-
-4 Estrat´egias de Processamento
-
-4.1 Pipeline Sequencial
-
-O pipeline sequencial ´e composto pelas seguintes etapas:
-   1. Validac¸a˜o
-   2. Filtro de status
-   3. Extrac¸a˜o de data
-   4. C´alculo de receita
-   5. Agrupamento e carga no banco
-
-                                                               4
-4.2 Pipeline Paralelo
-
-O pipeline paralelo divide os dados em N partes e aplica o mesmo fluxo em paralelo com uso de
-ThreadPool, utilizando Queue para comunica¸ca˜o entre etapas. Ap´os o processamento, ocorre a
-agrega¸ca˜o final para:
-
-    • Receita total
-
-    • Receita por cart˜ao
-
-    • Receita por pa´ıs do usua´rio
-
-5 Triggers
-
-O componente Trigger ´e responsa´vel por iniciar a execuc¸a˜o do pipeline de forma automatizada
-ou sob demanda. A interface ´e simples e gen´erica, suportando o registro de um callback (func¸a˜o
-de retorno) a ser chamado quando o disparo ocorrer. Duas implementa¸c˜oes espec´ıficas foram
-desenvolvidas:
-
-    • TimerTrigger: dispara o callback periodicamente com base em um intervalo de tempo fixo,
-       definido em milissegundos no construtor. Internamente, utiliza uma thread que executa
-       um loop com sleep for(), verificando a condic¸a˜o de execuc¸˜ao e chamando o callback se
-       apropriado. Essa abordagem ´e u´til para pipelines agendados, como coletas peri´odicas de
-       dados.
-
-    • RequestTrigger: permite o disparo manual via o m´etodo trigger(). E´ u´til em cena´rios em
-       que o pipeline deve ser executado sob demanda, como por meio de uma requisi¸c˜ao ou evento
-       do sistema.
-
-A flexibilidade dessa estrutura permite que novos modos de disparo possam ser facilmente inte-
-grados ao sistema herdando da classe Trigger.
-
-6 Benchmarking
-
-Durante a execu¸ca˜o, s˜ao registrados os tempos de:
-
-• Processamento
-• Carga no banco
-
-As m´etricas s˜ao coletadas para os seguintes cen´arios:
-
-                  Pipeline                            Threads
-                  Sequencial                          1
-                  Paralelo                            4
-                  Paralelo                            8
-                  Paralelo                            12
-
-Os tempos s˜ao armazenados na estrutura TestResults e impressos em formato tabular.
-
-7 Resultados
-
-7.1 Tempo
-
-Para avaliar o desempenho do pipeline desenvolvido, foi realizado um benchmark utilizando um
-arquivo JSON contendo 100 mil registros, chamado ordersCemMil. Os tempos foram medidos em
-milissegundos (ms) para as duas etapas principais: Processamento (handlers) e Carga (inser¸ca˜o
-em banco de dados SQLite).
-Os testes consideraram trˆes cen´arios:
-
-                              5
-            Figura 2: Tempo de execu¸c˜ao em milissegundos para o arquivo ordersCemMil.
-
-Os resultados obtidos mostram claramente o impacto positivo do paralelismo na etapa de proces-
-samento, embora os ganhos na etapa de carregamento no banco (SQLite) sejam limitados:
-
-    • O tempo de processamento foi significativamente reduzido ao aplicar mu´ltiplas threads: de
-       12.263 ms na execuc¸˜ao sequencial para 1.305 ms com 4 threads, 1.099 ms com 8 threads,
-       e 722 ms com 12 threads. Isso representa uma redu¸c˜ao de at´e 94%, evidenciando a eficiˆencia
-       da paraleliza¸c˜ao nessa etapa.
-
-    • Em contrapartida, o tempo de carga no SQLite apresentou um comportamento mais
-       insta´vel. Apesar de uma leve melhoria com 4 threads (7.690 ms), o tempo aumentou com
-       8 threads (9.694 ms) e oscilou com 12 threads (8.420 ms). Esse comportamento est´a rela-
-       cionado `as limita¸c˜oes de concorrˆencia do SQLite, que tende a serializar operac¸˜oes de escrita,
-       impactando negativamente a escalabilidade.
-
-No total, foram processadas 97.015 linhas em 6 execu¸c˜oes, demonstrando a robustez e con-
-sistˆencia do pipeline proposto mesmo em cena´rios de carga elevada.
-
-7.2 Estat´ısticas
-
-Al´em dos benchmarks de desempenho, foi implementado um mecanismo de valida¸ca˜o da con-
-sistˆencia dos dados processados. Durante a gerac¸a˜o sint´etica dos dados de entrada (especialmente
-no arquivo ordersCemMil), foram atribu´ıdos pesos probabil´ısticos a diferentes categorias —
-como tipos de cart˜ao, destinos e tipos de assento — influenciando diretamente a frequˆencia com
-que cada categoria aparece nos dados. Ap´os o carregamento no SQLite, ´e poss´ıvel realizar con-
-sultas agregadas que permitem comparar as distribuic¸o˜es observadas com os pesos definidos no
-gerador, servindo como forma de verifica¸c˜ao da integridade e coerˆencia da pipeline de ETL. Esse
-processo garante que o sistema est´a respeitando corretamente as propor¸c˜oes dos dados simulados
-e preservando sua estrutura estat´ıstica ao longo de todas as etapas de extra¸c˜ao, transformac¸˜ao e
-carga.
-
-                                                               6
-                       Figura 3: Gr´aficos resultantes com o tratamento dos handlers.
-    • A receita di´aria manteve-se relativamente esta´vel ao longo do tempo, com varia¸c˜oes naturais
-
-       entre os dias.
-    • O cart˜ao de cr´edito foi o m´etodo de pagamento mais utilizado, seguido por cart˜ao de
-
-       d´ebito e Pix.
-    • O Brasil apresentou a maior receita entre todos os pa´ıses, sendo tamb´em o principal destino
-
-       em nu´mero de reservas.
-    • A classe econˆomica gerou significativamente mais receita do que a primeira classe.
-    • Os 10 voos mais reservados tiveram entre 30 e 35 reservas, com boa distribui¸c˜ao de
-
-       demanda entre eles.
-    • Entre os destinos, o Brasil liderou com folga em nu´mero de voos reservados, refletindo os
-
-       pesos definidos no gerador de dados.
-Esses resultados indicam que o pipeline de ETL est´a funcionando corretamente, preservando a
-estrutura estat´ıstica dos dados e refletindo fielmente os padr˜oes esperados. Al´em disso, a visua-
-liza¸c˜ao gr´afica permite validar rapidamente a coerˆencia e consistˆencia das transforma¸co˜es realizadas
-durante o processo.
-
-                                                               7
-
diff --git a/databases/.gitkeep b/databases/.gitkeep
new file mode 100644
index 0000000..e69de29
diff --git a/databases/Database.db b/databases/Database.db
deleted file mode 100644
index b8cb3de..0000000
Binary files a/databases/Database.db and /dev/null differ
diff --git "a/gRPC_Relat\303\263rio.pdf" "b/gRPC_Relat\303\263rio.pdf"
new file mode 100644
index 0000000..03f379a
--- /dev/null
+++ "b/gRPC_Relat\303\263rio.pdf"
@@ -0,0 +1,204 @@
+          Funda¸ca˜o Getu´lio Vargas
+EMAp - Escola de Matem´atica Aplicada
+Ciˆencia de Dados e Inteligˆencia Artificial
+
+           Computa¸ca˜o Escal´avel
+
+           RPC
+
+                Guilherme Buss
+             Guilherme Carvalho
+
+               Gustavo Bianchi
+                  Joa˜o Gabriel
+
+             Vin´ıcius Nascimento
+
+                 Rio de Janeiro
+                       2025
+1 Solu¸c˜ao Arquitetural e Decis˜oes de Projeto
+
+Neste projeto, atualizamos a arquitetura original do sistema ETL, que processava dados a partir
+de arquivos locais, para uma arquitetura distribu´ıda baseada em RPC (Remote Procedure Call).
+
+1.1 Arquitetura Original
+
+Na soluc¸a˜o inicial, a comunica¸ca˜o entre o simulador das fontes de dados e o pipeline ETL era
+feita por meio de arquivos intermedia´rios, onde os dados eram gerados por scripts Python em
+arquivos CSV/JSON, posteriormente lidos e processados pelo ETL implementado em C++. Essa
+abordagem limitava a execu¸ca˜o a uma u´nica ma´quina e introduzia latˆencias relacionadas `a escrita
+e leitura de disco, que ´e bem mais lenta que apenas passar os dados diretamente ap´os serem
+”criados”.
+
+1.2 Nova Arquitetura com RPC
+
+Implementamos um mecanismo de comunica¸ca˜o via gRPC https://grpc.io/, onde mu´ltiplos
+clientes Python simuladores enviam eventos diretamente para o servidor ETL em C++ via rede,
+eliminando a necessidade de arquivos intermedi´arios. Os eventos sa˜o transmitidos no formato
+serializado definido por um arquivo .proto, garantindo interoperabilidade entre as linguagens.
+
+1.3 Decis˜oes de Projeto
+
+    • Uso do gRPC: Escolhemos gRPC pela sua performance, suporte a mu´ltiplas linguagens e
+       facilidade de definic¸˜ao dos contratos via Protobuf. Enquanto nossos clientes foram feitos em
+       Python, nosso servidor ´e em C++.
+
+    • Cliente em Python: Respons´avel pela gerac¸˜ao de dados de teste com bibliotecas como
+       Faker e Pandas, al´em de permitir simular mu´ltiplas instaˆncias concorrentes.
+
+    • Servidor em C++: Recebe os dados do cliente Python e processa-os no pipeline ETL.
+    • Medida de latˆencia: Agora coletamos timestamps nos eventos para medir a latˆencia de
+
+       ponta a ponta, entre a gerac¸a˜o do evento no cliente e seu processamento no servidor.
+    • Elimina¸c˜ao de arquivos intermedi´arios: Substituindo o armazenamento em disco pela
+
+       comunica¸c˜ao direta via rede, reduzimos a latˆencia e aumentamos a escalabilidade.
+
+1.4 Melhorias Implementadas
+
+Antes, os dados eram gerados em massa, salvos em arquivos CSV e depois processados, o que
+introduzia gargalos e dificultava testes em ambientes distribu´ıdos. Com o RPC:
+
+    • Os clientes Python geram eventos em tempo real, enviando-os diretamente ao servidor.
+    • O servidor recebe e processa os eventos imediatamente, mantendo a mesma estrutura paralela
+
+       do pipeline.
+    • O sistema permite mu´ltiplos clientes concorrentes enviando eventos simultaneamente, simu-
+
+       lando cargas reais distribu´ıdas em rede.
+    • A arquitetura facilita a expansa˜o para o uso de mu´ltiplas ma´quinas simultaneamente, o que
+
+       o uso e cria¸ca˜o de arquivos na˜o permitia.
+
+Essas mudan¸cas representam uma evoluc¸a˜o na arquitetura, permitindo maior escalabilidade, menor
+latˆencia e maior fidelidade no teste de carga e ana´lise de desempenho do sistema.
+
+2 Configura¸c˜ao do Ambiente e Uso do WSL
+
+Durante o desenvolvimento da integrac¸a˜o entre o cliente Python e o servidor ETL em C++ utili-
+zando gRPC, enfrentamos dificuldades para executar o gRPC diretamente em ma´quinas Windows.
+Para fazer funcionar, utilizamos o WSL (Windows Subsystem for Linux), que oferece um
+ambiente Linux completo dentro do Windows, garantindo maior compatibilidade e estabilidade,.
+
+                                                               1
+2.1 Motiva¸c˜ao para Uso do WSL
+
+O gRPC em C++ depende de v´arias bibliotecas e ferramentas que possuem suporte limitado ou
+apresentam instabilidades no ambiente Windows tradicional. O WSL fornece um sistema Linux
+real, onde as ferramentas de desenvolvimento, bibliotecas e o compilador protoc do Protocol Buffers
+podem ser instalados e utilizados sem restri¸c˜oes, permitindo compilar e executar o servidor gRPC
+de forma confi´avel.
+
+2.2 Configura¸c˜ao do Ambiente
+
+Foi necess´ario instalar diversos pacotes essenciais para desenvolvimento, compilac¸a˜o e execu¸ca˜o do
+projeto, incluindo compiladores, ferramentas de build e bibliotecas como SQLite (para o banco de
+dados SQL), gRPC, Protocol Buffers e suas dependˆencias. Esses componentes permitiram:
+
+    • Compilar o servidor C++ com suporte a gRPC e SQLite.
+    • Gerar os arquivos fonte a partir do arquivo .proto para C++ e Python.
+    • Executar o cliente Python com as bibliotecas gRPC necess´arias.
+
+Para facilitar o processo, reutilizamos a estrutura baseada em Makefile ja´ empregada no projeto
+final da A1. O Makefile gerencia a compila¸ca˜o dos arquivos protobuf, a ligac¸˜ao com as bibliotecas
+e a gerac¸a˜o dos execut´aveis, tornando o build simples e reproduz´ıvel dentro do WSL.
+
+2.3 Compila¸c˜ao e Execu¸c˜ao
+
+Os comandos b´asicos para gera¸ca˜o dos arquivos protobuf foram:
+
+# Para C++
+protoc --grpc_out=. --plugin=protoc-gen-grpc=$(which grpc_cpp_plugin) event.proto
+protoc --cpp_out=. event.proto
+
+# Para Python (no ambiente Python/venv)
+python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. event.proto
+
+Na pasta src do projeto, a compila¸c˜ao e execu¸ca˜o do servidor s˜ao feitas via make, apenas escrevendo
+make nesse ambiente, o que roda o nosso MakeFile.
+O servidor gRPC foi executado dentro do WSL, enquanto os clientes Python puderam rodar
+em terminais externos, tanto no WSL quanto no Windows, conectando-se ao servidor via rede
+local (localhost). Essa configurac¸˜ao facilitou testes e simula¸ca˜o de mu´ltiplos clientes concorrentes,
+aproximando-se de um cena´rio real distribu´ıdo e possibilitando expans˜ao para mu´ltiplas m´aquinas.
+
+3 Discuss˜ao sobre Alternativas de Comunica¸c˜ao
+
+Al´em da abordagem adotada com gRPC, existem outras maneiras via´veis para implementar a
+comunica¸c˜ao entre o simulador das fontes de dados e o pipeline ETL, como:
+
+    • Cliente e servidor ambos em Python: Usar uma solu¸ca˜o 100% Python com bibliotecas
+       como Flask, FastAPI ou ZeroMQ.
+
+    • Comunica¸c˜ao baseada em arquivos ou banco de dados compartilhado: Manter o
+       uso de arquivos CSV, JSON ou banco de dados como meio intermedi´ario.
+
+    • REST APIs: Expor o ETL como um servic¸o RESTful consumido pelo simulador via HTTP..
+
+3.1 Justificativa da Escolha pelo gRPC
+
+Optamos pelo gRPC com cliente Python e servidor C++ devido a:
+
+    • Alto desempenho: Uso de HTTP/2 e Protobuf garante comunica¸ca˜o ra´pida e eficiente,
+       essencial para testes de carga e processamento em tempo real.
+
+                                                               2
+• Multilinguagem: Gera¸ca˜o automa´tica dos stubs facilita a integra¸c˜ao entre simulador Python
+   e ETL em C++, evitando serializac¸a˜o manual.
+
+• Comunica¸c˜ao s´ıncrona e escal´avel: Permite comunicac¸˜ao direta entre ma´quinas, supe-
+   rando limita¸co˜es de arquivos locais e melhorando escalabilidade horizontal.
+
+• Facilidade de manuten¸c˜ao: Contrato de dados centralizado via .proto reduz erros de
+   incompatibilidade.
+
+4 Resultados
+
+Para avaliar o desempenho da arquitetura RPC implementada entre o simulador e o pipeline ETL,
+foram realizados testes de carga variando o nu´mero de instaˆncias do simulador de 1 a 20. Em cada
+experimento, foi computado o tempo m´edio de resposta, definido como o intervalo entre o envio
+de um evento pelo simulador e a conclus˜ao da sua ana´lise pelo pipeline ETL.
+No arquivo response times.csv da pasta gRPC do nosso reposit´orio, ´e poss´ıvel ver nossos resultados:
+
+Nº de Clientes  Tempo M´edio de Resposta (s)
+          1                       0.9507
+          2                       1.2076
+          3                       1.3628
+          4                       1.7969
+          5                       1.8896
+          6                       2.4543
+          7                       2.9994
+          8                       3.2603
+          8                       3.8493
+          9                       4.4664
+         10                       4.9240
+         11                       5.4684
+         12                       6.1036
+         13                       8.0591
+         14                       7.7512
+         15                       7.7095
+         16                       10.8900
+         17                       10.6146
+         18                       9.5894
+         19                       10.6811
+         20                       13.6880
+
+Tabela 1: Tempo m´edio de resposta em fun¸ca˜o do nu´mero de clientes simultaˆneos
+
+Podemos ver que ha´ um crescimento no tempo m´edio de resposta conforme o nu´mero de clientes
+aumenta, o que era esperado dado o maior volume de requisic¸˜oes concorrentes sendo processadas
+pelo servidor ETL. At´e cerca de 8 a 12 clientes, o sistema manteve um crescimento (relativamente)
+linear e controlado no tempo de resposta. No entanto, a partir de 13 clientes, ha´ um salto mais
+significativo nos tempos. Isso, provavelmente, ´e causado por uma poss´ıvel satura¸c˜ao dos recursos
+computacionais da ma´quina servidora.
+Ainda assim, a solu¸c˜ao baseada em RPC demonstrou escalabilidade razo´avel, mantendo o funcio-
+namento do sistema mesmo sob carga elevada, com at´e 20 clientes simultaˆneos.
+
+5 Conclus˜ao
+
+Considerando o projeto como um todo e a necessidade de escalar para mu´ltiplas m´aquinas, diversi-
+ficar clientes e reduzir latˆencia, o uso do gRPC com cliente Python e servidor C++ oferece o melhor
+equil´ıbrio entre desempenho, interoperabilidade e escalabilidade, alinhando-se perfeitamente aos
+objetivos da comunicac¸a˜o eficiente entre simulador e pipeline ETL distribu´ıdo.
+
+                3
+
diff --git "a/gRPC_Relat\303\263rio_Final.pdf" "b/gRPC_Relat\303\263rio_Final.pdf"
new file mode 100644
index 0000000..9bd3b21
--- /dev/null
+++ "b/gRPC_Relat\303\263rio_Final.pdf"
@@ -0,0 +1,205 @@
+          Funda¸ca˜o Getu´lio Vargas
+EMAp - Escola de Matem´atica Aplicada
+Ciˆencia de Dados e Inteligˆencia Artificial
+
+           Computa¸ca˜o Escal´avel
+
+           RPC
+
+                Guilherme Buss
+             Guilherme Carvalho
+
+               Gustavo Bianchi
+                  Joa˜o Gabriel
+
+             Vin´ıcius Nascimento
+
+                 Rio de Janeiro
+                       2025
+1 Solu¸c˜ao Arquitetural e Decis˜oes de Projeto
+
+Neste projeto, atualizamos a arquitetura original do sistema ETL, que processava dados a partir
+de arquivos locais, para uma arquitetura distribu´ıda baseada em RPC (Remote Procedure Call).
+
+1.1 Arquitetura Original
+
+Na soluc¸a˜o inicial, a comunica¸ca˜o entre o simulador das fontes de dados e o pipeline ETL era
+feita por meio de arquivos intermedia´rios, onde os dados eram gerados por scripts Python em
+arquivos CSV/JSON, posteriormente lidos e processados pelo ETL implementado em C++. Essa
+abordagem limitava a execu¸ca˜o a uma u´nica ma´quina e introduzia latˆencias relacionadas `a escrita
+e leitura de disco, que ´e bem mais lenta que apenas passar os dados diretamente ap´os serem
+”criados”.
+
+1.2 Nova Arquitetura com RPC
+
+Implementamos um mecanismo de comunica¸ca˜o via gRPC https://grpc.io/, onde mu´ltiplos
+clientes Python simuladores enviam eventos diretamente para o servidor ETL em C++ via rede,
+eliminando a necessidade de arquivos intermedi´arios. Os eventos sa˜o transmitidos no formato
+serializado definido por um arquivo .proto, garantindo interoperabilidade entre as linguagens.
+
+1.3 Decis˜oes de Projeto
+
+    • Uso do gRPC: Escolhemos gRPC pela sua performance, suporte a mu´ltiplas linguagens e
+       facilidade de definic¸˜ao dos contratos via Protobuf. Enquanto nossos clientes foram feitos em
+       Python, nosso servidor ´e em C++.
+
+    • Cliente em Python: Respons´avel pela gerac¸˜ao de dados de teste com bibliotecas como
+       Faker e Pandas, al´em de permitir simular mu´ltiplas instaˆncias concorrentes.
+
+    • Servidor em C++: Recebe os dados do cliente Python e processa-os no pipeline ETL.
+    • Medida de latˆencia: Agora coletamos timestamps nos eventos para medir a latˆencia de
+
+       ponta a ponta, entre a gerac¸a˜o do evento no cliente e seu processamento no servidor.
+    • Elimina¸c˜ao de arquivos intermedi´arios: Substituindo o armazenamento em disco pela
+
+       comunica¸c˜ao direta via rede, reduzimos a latˆencia e aumentamos a escalabilidade.
+
+1.4 Melhorias Implementadas
+
+Antes, os dados eram gerados em massa, salvos em arquivos CSV e depois processados, o que
+introduzia gargalos e dificultava testes em ambientes distribu´ıdos. Com o RPC:
+
+    • Os clientes Python geram eventos em tempo real, enviando-os diretamente ao servidor.
+    • O servidor recebe e processa os eventos imediatamente, mantendo a mesma estrutura paralela
+
+       do pipeline.
+    • O sistema permite mu´ltiplos clientes concorrentes enviando eventos simultaneamente, simu-
+
+       lando cargas reais distribu´ıdas em rede.
+    • A arquitetura facilita a expansa˜o para o uso de mu´ltiplas ma´quinas simultaneamente, o que
+
+       o uso e cria¸ca˜o de arquivos na˜o permitia.
+
+Essas mudan¸cas representam uma evoluc¸a˜o na arquitetura, permitindo maior escalabilidade, menor
+latˆencia e maior fidelidade no teste de carga e ana´lise de desempenho do sistema.
+
+2 Configura¸c˜ao do Ambiente e Uso do WSL
+
+Durante o desenvolvimento da integrac¸a˜o entre o cliente Python e o servidor ETL em C++ utili-
+zando gRPC, enfrentamos dificuldades para executar o gRPC diretamente em ma´quinas Windows.
+Para fazer funcionar, utilizamos o WSL (Windows Subsystem for Linux), que oferece um
+ambiente Linux completo dentro do Windows, garantindo maior compatibilidade e estabilidade,.
+
+                                                               1
+2.1 Motiva¸c˜ao para Uso do WSL
+
+O gRPC em C++ depende de v´arias bibliotecas e ferramentas que possuem suporte limitado ou
+apresentam instabilidades no ambiente Windows tradicional. O WSL fornece um sistema Linux
+real, onde as ferramentas de desenvolvimento, bibliotecas e o compilador protoc do Protocol Buffers
+podem ser instalados e utilizados sem restri¸c˜oes, permitindo compilar e executar o servidor gRPC
+de forma confi´avel.
+
+2.2 Configura¸c˜ao do Ambiente
+
+Foi necess´ario instalar diversos pacotes essenciais para desenvolvimento, compilac¸a˜o e execu¸ca˜o do
+projeto, incluindo compiladores, ferramentas de build e bibliotecas como SQLite (para o banco de
+dados SQL), gRPC, Protocol Buffers e suas dependˆencias. Esses componentes permitiram:
+
+    • Compilar o servidor C++ com suporte a gRPC e SQLite.
+    • Gerar os arquivos fonte a partir do arquivo .proto para C++ e Python.
+    • Executar o cliente Python com as bibliotecas gRPC necess´arias.
+
+Para facilitar o processo, reutilizamos a estrutura baseada em Makefile ja´ empregada no projeto
+final da A1. O Makefile gerencia a compila¸ca˜o dos arquivos protobuf, a ligac¸˜ao com as bibliotecas
+e a gerac¸a˜o dos execut´aveis, tornando o build simples e reproduz´ıvel dentro do WSL.
+
+2.3 Compila¸c˜ao e Execu¸c˜ao
+
+Os comandos b´asicos para gera¸ca˜o dos arquivos protobuf foram:
+
+# Para C++
+protoc --grpc_out=. --plugin=protoc-gen-grpc=$(which grpc_cpp_plugin) event.proto
+protoc --cpp_out=. event.proto
+
+# Para Python (no ambiente Python/venv)
+python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. event.proto
+
+Na pasta src do projeto, a compila¸c˜ao e execu¸ca˜o do servidor s˜ao feitas via make, apenas escrevendo
+make nesse ambiente, o que roda o nosso MakeFile.
+O servidor gRPC foi executado dentro do WSL, enquanto os clientes Python puderam rodar
+em terminais externos, tanto no WSL quanto no Windows, conectando-se ao servidor via rede
+local (localhost). Essa configurac¸˜ao facilitou testes e simula¸ca˜o de mu´ltiplos clientes concorrentes,
+aproximando-se de um cena´rio real distribu´ıdo e possibilitando expans˜ao para mu´ltiplas m´aquinas.
+
+3 Discuss˜ao sobre Alternativas de Comunica¸c˜ao
+
+Al´em da abordagem adotada com gRPC, existem outras maneiras via´veis para implementar a
+comunica¸c˜ao entre o simulador das fontes de dados e o pipeline ETL, como:
+
+    • Cliente e servidor ambos em Python: Usar uma solu¸ca˜o 100% Python com bibliotecas
+       como Flask, FastAPI ou ZeroMQ.
+
+    • Comunica¸c˜ao baseada em arquivos ou banco de dados compartilhado: Manter o
+       uso de arquivos CSV, JSON ou banco de dados como meio intermedi´ario.
+
+    • REST APIs: Expor o ETL como um servic¸o RESTful consumido pelo simulador via HTTP..
+
+3.1 Justificativa da Escolha pelo gRPC
+
+Optamos pelo gRPC com cliente Python e servidor C++ devido a:
+
+    • Alto desempenho: Uso de HTTP/2 e Protobuf garante comunica¸ca˜o ra´pida e eficiente,
+       essencial para testes de carga e processamento em tempo real.
+
+                                                               2
+• Multilinguagem: Gera¸c˜ao autom´atica dos stubs facilita a integra¸c˜ao entre simulador Python
+   e ETL em C++, evitando serializac¸a˜o manual.
+
+• Comunica¸c˜ao s´ıncrona e escal´avel: Permite comunicac¸a˜o direta entre m´aquinas, supe-
+   rando limita¸c˜oes de arquivos locais e melhorando escalabilidade horizontal.
+
+• Facilidade de manuten¸c˜ao: Contrato de dados centralizado via .proto reduz erros de
+   incompatibilidade.
+
+4 Resultados
+
+Para avaliar o desempenho da arquitetura RPC implementada entre o simulador e o pipeline ETL,
+foram realizados testes de carga variando o nu´mero de instˆancias do simulador de 1 a 20. Em cada
+experimento, foi computado o tempo m´edio de resposta, definido como o intervalo entre o envio
+de um evento pelo simulador e a conclus˜ao da sua ana´lise pelo pipeline ETL.
+No arquivo response times.csv da pasta gRPC do nosso reposit´orio, ´e poss´ıvel ver nossos resultados,
+em que os testes foram feitos com 4 threads:
+
+Nº de Clientes  Tempo M´edio de Resposta (s)
+          1                       0.9507
+          2                       1.2076
+          3                       1.3628
+          4                       1.7969
+          5                       1.8896
+          6                       2.4543
+          7                       2.9994
+          8                       3.2603
+          8                       3.8493
+          9                       4.4664
+         10                       4.9240
+         11                       5.4684
+         12                       6.1036
+         13                       8.0591
+         14                       7.7512
+         15                       7.7095
+         16                       10.8900
+         17                       10.6146
+         18                       9.5894
+         19                       10.6811
+         20                       13.6880
+
+Tabela 1: Tempo m´edio de resposta em fun¸c˜ao do nu´mero de clientes simultaˆneos
+
+Podemos ver que ha´ um crescimento no tempo m´edio de resposta conforme o nu´mero de clientes
+aumenta, o que era esperado dado o maior volume de requisic¸˜oes concorrentes sendo processadas
+pelo servidor ETL. At´e cerca de 8 a 12 clientes, o sistema manteve um crescimento (relativamente)
+linear e controlado no tempo de resposta. No entanto, a partir de 13 clientes, ha´ um salto mais
+significativo nos tempos. Isso, provavelmente, ´e causado por uma poss´ıvel satura¸ca˜o dos recursos
+computacionais da m´aquina servidora.
+Ainda assim, a solu¸c˜ao baseada em RPC demonstrou escalabilidade razo´avel, mantendo o funcio-
+namento do sistema mesmo sob carga elevada, com at´e 20 clientes simultaˆneos.
+
+5 Conclus˜ao
+
+Considerando o projeto como um todo e a necessidade de escalar para mu´ltiplas ma´quinas, diversi-
+ficar clientes e reduzir latˆencia, o uso do gRPC com cliente Python e servidor C++ oferece o melhor
+equil´ıbrio entre desempenho, interoperabilidade e escalabilidade, alinhando-se perfeitamente aos
+objetivos da comunicac¸˜ao eficiente entre simulador e pipeline ETL distribu´ıdo.
+
+                3
+
diff --git a/grpc/__pycache__/event_pb2.cpython-312.pyc b/grpc/__pycache__/event_pb2.cpython-312.pyc
new file mode 100644
index 0000000..c65a64c
Binary files /dev/null and b/grpc/__pycache__/event_pb2.cpython-312.pyc differ
diff --git a/grpc/__pycache__/event_pb2_grpc.cpython-312.pyc b/grpc/__pycache__/event_pb2_grpc.cpython-312.pyc
new file mode 100644
index 0000000..969448d
Binary files /dev/null and b/grpc/__pycache__/event_pb2_grpc.cpython-312.pyc differ
diff --git a/grpc/client.py b/grpc/client.py
new file mode 100644
index 0000000..7755adc
--- /dev/null
+++ b/grpc/client.py
@@ -0,0 +1,125 @@
+import grpc
+import time
+import random
+import event_pb2
+import event_pb2_grpc
+import pandas as pd
+from faker import Faker
+from concurrent import futures
+import csv
+import os
+
+faker = Faker()
+
+# Configuração do arquivo de resultados
+RESULTS_FILE = "response_times.csv"
+if not os.path.exists(RESULTS_FILE):
+    with open(RESULTS_FILE, 'w', newline='') as f:
+        writer = csv.writer(f)
+        writer.writerow(["num_clients", "avg_response_time"])
+
+df_users = pd.read_csv("../generator/users.csv")
+user_map = df_users.set_index("user_id")["username"].to_dict()
+user_ids = list(user_map.keys())
+
+df_seats = pd.read_csv("../generator/flights_seats.csv")
+df_available_seats = df_seats[df_seats["taken"] == 0].copy()
+
+assert len(df_available_seats) > 0, "Não há assentos disponíveis!"
+
+def generate_random_event():
+    seat_row = df_available_seats.sample(n=1).iloc[0]
+    flight_id = f"AAA-{seat_row['flight_id']}"
+    seat = seat_row["seat"]
+    price = round(seat_row["price"], 2)
+
+    user_id = random.choice(user_ids)
+    customer_name = user_map[user_id]
+
+    status = random.choices(
+        ["pending", "confirmed", "cancelled"],
+        weights=[0.05, 0.90, 0.05],
+        k=1
+    )[0]
+
+    payment_method = random.choices(
+        ["credit_card", "debit_card", "pix", "paypal"],
+        weights=[0.46, 0.34, 0.17, 0.03],
+        k=1
+    )[0]
+
+    reservation_time = faker.date_time_between(start_date="-600d", end_date="now").isoformat()
+    timestamp = int(time.time() * 1000)
+
+    return event_pb2.Event(
+        flight_id=flight_id,
+        seat=seat,
+        user_id=str(user_id),
+        customer_name=customer_name,
+        status=status,
+        payment_method=payment_method,
+        reservation_time=reservation_time,
+        price=str(price),
+        timestamp=timestamp
+    )
+
+def run(client_id=0, repetitions=5, sleep_between=1):
+    channel = grpc.insecure_channel('localhost:50051')
+    stub = event_pb2_grpc.EventServiceStub(channel)
+    response_times = []
+
+    for i in range(repetitions):
+        event = generate_random_event()
+        start_time = time.perf_counter()
+        
+        try:
+            response = stub.SendEvent(event)
+            end_time = time.perf_counter()
+            response_time = end_time - start_time
+            response_times.append(response_time)
+            
+            print(f"[Client {client_id}] Received: {response.message} | Time: {response_time:.4f}s")
+            
+        except grpc.RpcError as e:
+            end_time = time.perf_counter()
+            response_time = end_time - start_time
+            response_times.append(response_time)
+            
+            # Captura a mensagem de erro do servidor
+            status_code = e.code()
+            details = e.details()
+            
+            print(f"[Client {client_id}] Received: Cadastro inválido | Time: {response_time:.4f}s")
+        
+        time.sleep(sleep_between)
+    
+    return response_times
+
+if __name__ == '__main__':
+    import sys
+    import threading
+    import numpy as np
+
+    num_clients = int(sys.argv[1]) if len(sys.argv) > 1 else 1
+    events_per_client = int(sys.argv[2]) if len(sys.argv) > 2 else 5
+
+    threads = []
+    all_response_times = []
+
+    # Executa os clientes
+    for i in range(num_clients):
+        t = threading.Thread(target=lambda: all_response_times.extend(run(i, events_per_client)))
+        t.start()
+        threads.append(t)
+
+    for t in threads:
+        t.join()
+
+    # Calcula a média e salva no arquivo
+    if all_response_times:
+        avg_time = np.mean(all_response_times)
+        print(f"\nMédia de tempo de resposta: {avg_time:.4f}s para {num_clients} clientes")
+        
+        with open(RESULTS_FILE, 'a', newline='') as f:
+            writer = csv.writer(f)
+            writer.writerow([num_clients, avg_time])
\ No newline at end of file
diff --git a/grpc/event.grpc.pb.cc b/grpc/event.grpc.pb.cc
new file mode 100644
index 0000000..133785f
--- /dev/null
+++ b/grpc/event.grpc.pb.cc
@@ -0,0 +1,86 @@
+// Generated by the gRPC C++ plugin.
+// If you make any local change, they will be lost.
+// source: event.proto
+
+#include "event.pb.h"
+#include "event.grpc.pb.h"
+
+#include <functional>
+#include <grpcpp/support/async_stream.h>
+#include <grpcpp/support/async_unary_call.h>
+#include <grpcpp/impl/channel_interface.h>
+#include <grpcpp/impl/client_unary_call.h>
+#include <grpcpp/support/client_callback.h>
+#include <grpcpp/support/message_allocator.h>
+#include <grpcpp/support/method_handler.h>
+#include <grpcpp/impl/rpc_service_method.h>
+#include <grpcpp/support/server_callback.h>
+#include <grpcpp/impl/codegen/server_callback_handlers.h>
+#include <grpcpp/server_context.h>
+#include <grpcpp/impl/service_type.h>
+#include <grpcpp/support/sync_stream.h>
+namespace events {
+
+static const char* EventService_method_names[] = {
+  "/events.EventService/SendEvent",
+};
+
+std::unique_ptr< EventService::Stub> EventService::NewStub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options) {
+  (void)options;
+  std::unique_ptr< EventService::Stub> stub(new EventService::Stub(channel, options));
+  return stub;
+}
+
+EventService::Stub::Stub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options)
+  : channel_(channel), rpcmethod_SendEvent_(EventService_method_names[0], options.suffix_for_stats(),::grpc::internal::RpcMethod::NORMAL_RPC, channel)
+  {}
+
+::grpc::Status EventService::Stub::SendEvent(::grpc::ClientContext* context, const ::events::Event& request, ::events::Ack* response) {
+  return ::grpc::internal::BlockingUnaryCall< ::events::Event, ::events::Ack, ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(channel_.get(), rpcmethod_SendEvent_, context, request, response);
+}
+
+void EventService::Stub::async::SendEvent(::grpc::ClientContext* context, const ::events::Event* request, ::events::Ack* response, std::function<void(::grpc::Status)> f) {
+  ::grpc::internal::CallbackUnaryCall< ::events::Event, ::events::Ack, ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(stub_->channel_.get(), stub_->rpcmethod_SendEvent_, context, request, response, std::move(f));
+}
+
+void EventService::Stub::async::SendEvent(::grpc::ClientContext* context, const ::events::Event* request, ::events::Ack* response, ::grpc::ClientUnaryReactor* reactor) {
+  ::grpc::internal::ClientCallbackUnaryFactory::Create< ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(stub_->channel_.get(), stub_->rpcmethod_SendEvent_, context, request, response, reactor);
+}
+
+::grpc::ClientAsyncResponseReader< ::events::Ack>* EventService::Stub::PrepareAsyncSendEventRaw(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) {
+  return ::grpc::internal::ClientAsyncResponseReaderHelper::Create< ::events::Ack, ::events::Event, ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(channel_.get(), cq, rpcmethod_SendEvent_, context, request);
+}
+
+::grpc::ClientAsyncResponseReader< ::events::Ack>* EventService::Stub::AsyncSendEventRaw(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) {
+  auto* result =
+    this->PrepareAsyncSendEventRaw(context, request, cq);
+  result->StartCall();
+  return result;
+}
+
+EventService::Service::Service() {
+  AddMethod(new ::grpc::internal::RpcServiceMethod(
+      EventService_method_names[0],
+      ::grpc::internal::RpcMethod::NORMAL_RPC,
+      new ::grpc::internal::RpcMethodHandler< EventService::Service, ::events::Event, ::events::Ack, ::grpc::protobuf::MessageLite, ::grpc::protobuf::MessageLite>(
+          [](EventService::Service* service,
+             ::grpc::ServerContext* ctx,
+             const ::events::Event* req,
+             ::events::Ack* resp) {
+               return service->SendEvent(ctx, req, resp);
+             }, this)));
+}
+
+EventService::Service::~Service() {
+}
+
+::grpc::Status EventService::Service::SendEvent(::grpc::ServerContext* context, const ::events::Event* request, ::events::Ack* response) {
+  (void) context;
+  (void) request;
+  (void) response;
+  return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
+}
+
+
+}  // namespace events
+
diff --git a/grpc/event.grpc.pb.h b/grpc/event.grpc.pb.h
new file mode 100644
index 0000000..0cb91f7
--- /dev/null
+++ b/grpc/event.grpc.pb.h
@@ -0,0 +1,240 @@
+// Generated by the gRPC C++ plugin.
+// If you make any local change, they will be lost.
+// source: event.proto
+#ifndef GRPC_event_2eproto__INCLUDED
+#define GRPC_event_2eproto__INCLUDED
+
+#include "event.pb.h"
+
+#include <functional>
+#include <grpcpp/generic/async_generic_service.h>
+#include <grpcpp/support/async_stream.h>
+#include <grpcpp/support/async_unary_call.h>
+#include <grpcpp/support/client_callback.h>
+#include <grpcpp/client_context.h>
+#include <grpcpp/completion_queue.h>
+#include <grpcpp/support/message_allocator.h>
+#include <grpcpp/support/method_handler.h>
+#include <grpcpp/impl/codegen/proto_utils.h>
+#include <grpcpp/impl/rpc_method.h>
+#include <grpcpp/support/server_callback.h>
+#include <grpcpp/impl/codegen/server_callback_handlers.h>
+#include <grpcpp/server_context.h>
+#include <grpcpp/impl/service_type.h>
+#include <grpcpp/impl/codegen/status.h>
+#include <grpcpp/support/stub_options.h>
+#include <grpcpp/support/sync_stream.h>
+
+namespace events {
+
+class EventService final {
+ public:
+  static constexpr char const* service_full_name() {
+    return "events.EventService";
+  }
+  class StubInterface {
+   public:
+    virtual ~StubInterface() {}
+    virtual ::grpc::Status SendEvent(::grpc::ClientContext* context, const ::events::Event& request, ::events::Ack* response) = 0;
+    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::events::Ack>> AsyncSendEvent(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) {
+      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::events::Ack>>(AsyncSendEventRaw(context, request, cq));
+    }
+    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::events::Ack>> PrepareAsyncSendEvent(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) {
+      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::events::Ack>>(PrepareAsyncSendEventRaw(context, request, cq));
+    }
+    class async_interface {
+     public:
+      virtual ~async_interface() {}
+      virtual void SendEvent(::grpc::ClientContext* context, const ::events::Event* request, ::events::Ack* response, std::function<void(::grpc::Status)>) = 0;
+      virtual void SendEvent(::grpc::ClientContext* context, const ::events::Event* request, ::events::Ack* response, ::grpc::ClientUnaryReactor* reactor) = 0;
+    };
+    typedef class async_interface experimental_async_interface;
+    virtual class async_interface* async() { return nullptr; }
+    class async_interface* experimental_async() { return async(); }
+   private:
+    virtual ::grpc::ClientAsyncResponseReaderInterface< ::events::Ack>* AsyncSendEventRaw(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) = 0;
+    virtual ::grpc::ClientAsyncResponseReaderInterface< ::events::Ack>* PrepareAsyncSendEventRaw(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) = 0;
+  };
+  class Stub final : public StubInterface {
+   public:
+    Stub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options = ::grpc::StubOptions());
+    ::grpc::Status SendEvent(::grpc::ClientContext* context, const ::events::Event& request, ::events::Ack* response) override;
+    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::events::Ack>> AsyncSendEvent(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) {
+      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::events::Ack>>(AsyncSendEventRaw(context, request, cq));
+    }
+    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::events::Ack>> PrepareAsyncSendEvent(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) {
+      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::events::Ack>>(PrepareAsyncSendEventRaw(context, request, cq));
+    }
+    class async final :
+      public StubInterface::async_interface {
+     public:
+      void SendEvent(::grpc::ClientContext* context, const ::events::Event* request, ::events::Ack* response, std::function<void(::grpc::Status)>) override;
+      void SendEvent(::grpc::ClientContext* context, const ::events::Event* request, ::events::Ack* response, ::grpc::ClientUnaryReactor* reactor) override;
+     private:
+      friend class Stub;
+      explicit async(Stub* stub): stub_(stub) { }
+      Stub* stub() { return stub_; }
+      Stub* stub_;
+    };
+    class async* async() override { return &async_stub_; }
+
+   private:
+    std::shared_ptr< ::grpc::ChannelInterface> channel_;
+    class async async_stub_{this};
+    ::grpc::ClientAsyncResponseReader< ::events::Ack>* AsyncSendEventRaw(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) override;
+    ::grpc::ClientAsyncResponseReader< ::events::Ack>* PrepareAsyncSendEventRaw(::grpc::ClientContext* context, const ::events::Event& request, ::grpc::CompletionQueue* cq) override;
+    const ::grpc::internal::RpcMethod rpcmethod_SendEvent_;
+  };
+  static std::unique_ptr<Stub> NewStub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options = ::grpc::StubOptions());
+
+  class Service : public ::grpc::Service {
+   public:
+    Service();
+    virtual ~Service();
+    virtual ::grpc::Status SendEvent(::grpc::ServerContext* context, const ::events::Event* request, ::events::Ack* response);
+  };
+  template <class BaseClass>
+  class WithAsyncMethod_SendEvent : public BaseClass {
+   private:
+    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
+   public:
+    WithAsyncMethod_SendEvent() {
+      ::grpc::Service::MarkMethodAsync(0);
+    }
+    ~WithAsyncMethod_SendEvent() override {
+      BaseClassMustBeDerivedFromService(this);
+    }
+    // disable synchronous version of this method
+    ::grpc::Status SendEvent(::grpc::ServerContext* /*context*/, const ::events::Event* /*request*/, ::events::Ack* /*response*/) override {
+      abort();
+      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
+    }
+    void RequestSendEvent(::grpc::ServerContext* context, ::events::Event* request, ::grpc::ServerAsyncResponseWriter< ::events::Ack>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
+      ::grpc::Service::RequestAsyncUnary(0, context, request, response, new_call_cq, notification_cq, tag);
+    }
+  };
+  typedef WithAsyncMethod_SendEvent<Service > AsyncService;
+  template <class BaseClass>
+  class WithCallbackMethod_SendEvent : public BaseClass {
+   private:
+    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
+   public:
+    WithCallbackMethod_SendEvent() {
+      ::grpc::Service::MarkMethodCallback(0,
+          new ::grpc::internal::CallbackUnaryHandler< ::events::Event, ::events::Ack>(
+            [this](
+                   ::grpc::CallbackServerContext* context, const ::events::Event* request, ::events::Ack* response) { return this->SendEvent(context, request, response); }));}
+    void SetMessageAllocatorFor_SendEvent(
+        ::grpc::MessageAllocator< ::events::Event, ::events::Ack>* allocator) {
+      ::grpc::internal::MethodHandler* const handler = ::grpc::Service::GetHandler(0);
+      static_cast<::grpc::internal::CallbackUnaryHandler< ::events::Event, ::events::Ack>*>(handler)
+              ->SetMessageAllocator(allocator);
+    }
+    ~WithCallbackMethod_SendEvent() override {
+      BaseClassMustBeDerivedFromService(this);
+    }
+    // disable synchronous version of this method
+    ::grpc::Status SendEvent(::grpc::ServerContext* /*context*/, const ::events::Event* /*request*/, ::events::Ack* /*response*/) override {
+      abort();
+      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
+    }
+    virtual ::grpc::ServerUnaryReactor* SendEvent(
+      ::grpc::CallbackServerContext* /*context*/, const ::events::Event* /*request*/, ::events::Ack* /*response*/)  { return nullptr; }
+  };
+  typedef WithCallbackMethod_SendEvent<Service > CallbackService;
+  typedef CallbackService ExperimentalCallbackService;
+  template <class BaseClass>
+  class WithGenericMethod_SendEvent : public BaseClass {
+   private:
+    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
+   public:
+    WithGenericMethod_SendEvent() {
+      ::grpc::Service::MarkMethodGeneric(0);
+    }
+    ~WithGenericMethod_SendEvent() override {
+      BaseClassMustBeDerivedFromService(this);
+    }
+    // disable synchronous version of this method
+    ::grpc::Status SendEvent(::grpc::ServerContext* /*context*/, const ::events::Event* /*request*/, ::events::Ack* /*response*/) override {
+      abort();
+      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
+    }
+  };
+  template <class BaseClass>
+  class WithRawMethod_SendEvent : public BaseClass {
+   private:
+    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
+   public:
+    WithRawMethod_SendEvent() {
+      ::grpc::Service::MarkMethodRaw(0);
+    }
+    ~WithRawMethod_SendEvent() override {
+      BaseClassMustBeDerivedFromService(this);
+    }
+    // disable synchronous version of this method
+    ::grpc::Status SendEvent(::grpc::ServerContext* /*context*/, const ::events::Event* /*request*/, ::events::Ack* /*response*/) override {
+      abort();
+      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
+    }
+    void RequestSendEvent(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
+      ::grpc::Service::RequestAsyncUnary(0, context, request, response, new_call_cq, notification_cq, tag);
+    }
+  };
+  template <class BaseClass>
+  class WithRawCallbackMethod_SendEvent : public BaseClass {
+   private:
+    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
+   public:
+    WithRawCallbackMethod_SendEvent() {
+      ::grpc::Service::MarkMethodRawCallback(0,
+          new ::grpc::internal::CallbackUnaryHandler< ::grpc::ByteBuffer, ::grpc::ByteBuffer>(
+            [this](
+                   ::grpc::CallbackServerContext* context, const ::grpc::ByteBuffer* request, ::grpc::ByteBuffer* response) { return this->SendEvent(context, request, response); }));
+    }
+    ~WithRawCallbackMethod_SendEvent() override {
+      BaseClassMustBeDerivedFromService(this);
+    }
+    // disable synchronous version of this method
+    ::grpc::Status SendEvent(::grpc::ServerContext* /*context*/, const ::events::Event* /*request*/, ::events::Ack* /*response*/) override {
+      abort();
+      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
+    }
+    virtual ::grpc::ServerUnaryReactor* SendEvent(
+      ::grpc::CallbackServerContext* /*context*/, const ::grpc::ByteBuffer* /*request*/, ::grpc::ByteBuffer* /*response*/)  { return nullptr; }
+  };
+  template <class BaseClass>
+  class WithStreamedUnaryMethod_SendEvent : public BaseClass {
+   private:
+    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
+   public:
+    WithStreamedUnaryMethod_SendEvent() {
+      ::grpc::Service::MarkMethodStreamed(0,
+        new ::grpc::internal::StreamedUnaryHandler<
+          ::events::Event, ::events::Ack>(
+            [this](::grpc::ServerContext* context,
+                   ::grpc::ServerUnaryStreamer<
+                     ::events::Event, ::events::Ack>* streamer) {
+                       return this->StreamedSendEvent(context,
+                         streamer);
+                  }));
+    }
+    ~WithStreamedUnaryMethod_SendEvent() override {
+      BaseClassMustBeDerivedFromService(this);
+    }
+    // disable regular version of this method
+    ::grpc::Status SendEvent(::grpc::ServerContext* /*context*/, const ::events::Event* /*request*/, ::events::Ack* /*response*/) override {
+      abort();
+      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
+    }
+    // replace default version of method with streamed unary
+    virtual ::grpc::Status StreamedSendEvent(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::events::Event,::events::Ack>* server_unary_streamer) = 0;
+  };
+  typedef WithStreamedUnaryMethod_SendEvent<Service > StreamedUnaryService;
+  typedef Service SplitStreamedService;
+  typedef WithStreamedUnaryMethod_SendEvent<Service > StreamedService;
+};
+
+}  // namespace events
+
+
+#endif  // GRPC_event_2eproto__INCLUDED
diff --git a/grpc/event.pb.cc b/grpc/event.pb.cc
new file mode 100644
index 0000000..b32b56f
--- /dev/null
+++ b/grpc/event.pb.cc
@@ -0,0 +1,921 @@
+// Generated by the protocol buffer compiler.  DO NOT EDIT!
+// source: event.proto
+
+#include "event.pb.h"
+
+#include <algorithm>
+
+#include <google/protobuf/io/coded_stream.h>
+#include <google/protobuf/extension_set.h>
+#include <google/protobuf/wire_format_lite.h>
+#include <google/protobuf/descriptor.h>
+#include <google/protobuf/generated_message_reflection.h>
+#include <google/protobuf/reflection_ops.h>
+#include <google/protobuf/wire_format.h>
+// @@protoc_insertion_point(includes)
+#include <google/protobuf/port_def.inc>
+
+PROTOBUF_PRAGMA_INIT_SEG
+
+namespace _pb = ::PROTOBUF_NAMESPACE_ID;
+namespace _pbi = _pb::internal;
+
+namespace events {
+PROTOBUF_CONSTEXPR Event::Event(
+    ::_pbi::ConstantInitialized): _impl_{
+    /*decltype(_impl_.flight_id_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
+  , /*decltype(_impl_.seat_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
+  , /*decltype(_impl_.user_id_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
+  , /*decltype(_impl_.customer_name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
+  , /*decltype(_impl_.status_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
+  , /*decltype(_impl_.payment_method_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
+  , /*decltype(_impl_.reservation_time_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
+  , /*decltype(_impl_.price_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
+  , /*decltype(_impl_.timestamp_)*/int64_t{0}
+  , /*decltype(_impl_._cached_size_)*/{}} {}
+struct EventDefaultTypeInternal {
+  PROTOBUF_CONSTEXPR EventDefaultTypeInternal()
+      : _instance(::_pbi::ConstantInitialized{}) {}
+  ~EventDefaultTypeInternal() {}
+  union {
+    Event _instance;
+  };
+};
+PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 EventDefaultTypeInternal _Event_default_instance_;
+PROTOBUF_CONSTEXPR Ack::Ack(
+    ::_pbi::ConstantInitialized): _impl_{
+    /*decltype(_impl_.message_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
+  , /*decltype(_impl_._cached_size_)*/{}} {}
+struct AckDefaultTypeInternal {
+  PROTOBUF_CONSTEXPR AckDefaultTypeInternal()
+      : _instance(::_pbi::ConstantInitialized{}) {}
+  ~AckDefaultTypeInternal() {}
+  union {
+    Ack _instance;
+  };
+};
+PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AckDefaultTypeInternal _Ack_default_instance_;
+}  // namespace events
+static ::_pb::Metadata file_level_metadata_event_2eproto[2];
+static constexpr ::_pb::EnumDescriptor const** file_level_enum_descriptors_event_2eproto = nullptr;
+static constexpr ::_pb::ServiceDescriptor const** file_level_service_descriptors_event_2eproto = nullptr;
+
+const uint32_t TableStruct_event_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
+  ~0u,  // no _has_bits_
+  PROTOBUF_FIELD_OFFSET(::events::Event, _internal_metadata_),
+  ~0u,  // no _extensions_
+  ~0u,  // no _oneof_case_
+  ~0u,  // no _weak_field_map_
+  ~0u,  // no _inlined_string_donated_
+  PROTOBUF_FIELD_OFFSET(::events::Event, _impl_.flight_id_),
+  PROTOBUF_FIELD_OFFSET(::events::Event, _impl_.seat_),
+  PROTOBUF_FIELD_OFFSET(::events::Event, _impl_.user_id_),
+  PROTOBUF_FIELD_OFFSET(::events::Event, _impl_.customer_name_),
+  PROTOBUF_FIELD_OFFSET(::events::Event, _impl_.status_),
+  PROTOBUF_FIELD_OFFSET(::events::Event, _impl_.payment_method_),
+  PROTOBUF_FIELD_OFFSET(::events::Event, _impl_.reservation_time_),
+  PROTOBUF_FIELD_OFFSET(::events::Event, _impl_.price_),
+  PROTOBUF_FIELD_OFFSET(::events::Event, _impl_.timestamp_),
+  ~0u,  // no _has_bits_
+  PROTOBUF_FIELD_OFFSET(::events::Ack, _internal_metadata_),
+  ~0u,  // no _extensions_
+  ~0u,  // no _oneof_case_
+  ~0u,  // no _weak_field_map_
+  ~0u,  // no _inlined_string_donated_
+  PROTOBUF_FIELD_OFFSET(::events::Ack, _impl_.message_),
+};
+static const ::_pbi::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
+  { 0, -1, -1, sizeof(::events::Event)},
+  { 15, -1, -1, sizeof(::events::Ack)},
+};
+
+static const ::_pb::Message* const file_default_instances[] = {
+  &::events::_Event_default_instance_._instance,
+  &::events::_Ack_default_instance_._instance,
+};
+
+const char descriptor_table_protodef_event_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
+  "\n\013event.proto\022\006events\"\264\001\n\005Event\022\021\n\tfligh"
+  "t_id\030\001 \001(\t\022\014\n\004seat\030\002 \001(\t\022\017\n\007user_id\030\003 \001("
+  "\t\022\025\n\rcustomer_name\030\004 \001(\t\022\016\n\006status\030\005 \001(\t"
+  "\022\026\n\016payment_method\030\006 \001(\t\022\030\n\020reservation_"
+  "time\030\007 \001(\t\022\r\n\005price\030\010 \001(\t\022\021\n\ttimestamp\030\t"
+  " \001(\003\"\026\n\003Ack\022\017\n\007message\030\001 \001(\t27\n\014EventSer"
+  "vice\022\'\n\tSendEvent\022\r.events.Event\032\013.event"
+  "s.Ackb\006proto3"
+  ;
+static ::_pbi::once_flag descriptor_table_event_2eproto_once;
+const ::_pbi::DescriptorTable descriptor_table_event_2eproto = {
+    false, false, 293, descriptor_table_protodef_event_2eproto,
+    "event.proto",
+    &descriptor_table_event_2eproto_once, nullptr, 0, 2,
+    schemas, file_default_instances, TableStruct_event_2eproto::offsets,
+    file_level_metadata_event_2eproto, file_level_enum_descriptors_event_2eproto,
+    file_level_service_descriptors_event_2eproto,
+};
+PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_event_2eproto_getter() {
+  return &descriptor_table_event_2eproto;
+}
+
+// Force running AddDescriptors() at dynamic initialization time.
+PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_event_2eproto(&descriptor_table_event_2eproto);
+namespace events {
+
+// ===================================================================
+
+class Event::_Internal {
+ public:
+};
+
+Event::Event(::PROTOBUF_NAMESPACE_ID::Arena* arena,
+                         bool is_message_owned)
+  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
+  SharedCtor(arena, is_message_owned);
+  // @@protoc_insertion_point(arena_constructor:events.Event)
+}
+Event::Event(const Event& from)
+  : ::PROTOBUF_NAMESPACE_ID::Message() {
+  Event* const _this = this; (void)_this;
+  new (&_impl_) Impl_{
+      decltype(_impl_.flight_id_){}
+    , decltype(_impl_.seat_){}
+    , decltype(_impl_.user_id_){}
+    , decltype(_impl_.customer_name_){}
+    , decltype(_impl_.status_){}
+    , decltype(_impl_.payment_method_){}
+    , decltype(_impl_.reservation_time_){}
+    , decltype(_impl_.price_){}
+    , decltype(_impl_.timestamp_){}
+    , /*decltype(_impl_._cached_size_)*/{}};
+
+  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
+  _impl_.flight_id_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.flight_id_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (!from._internal_flight_id().empty()) {
+    _this->_impl_.flight_id_.Set(from._internal_flight_id(), 
+      _this->GetArenaForAllocation());
+  }
+  _impl_.seat_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.seat_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (!from._internal_seat().empty()) {
+    _this->_impl_.seat_.Set(from._internal_seat(), 
+      _this->GetArenaForAllocation());
+  }
+  _impl_.user_id_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.user_id_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (!from._internal_user_id().empty()) {
+    _this->_impl_.user_id_.Set(from._internal_user_id(), 
+      _this->GetArenaForAllocation());
+  }
+  _impl_.customer_name_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.customer_name_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (!from._internal_customer_name().empty()) {
+    _this->_impl_.customer_name_.Set(from._internal_customer_name(), 
+      _this->GetArenaForAllocation());
+  }
+  _impl_.status_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.status_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (!from._internal_status().empty()) {
+    _this->_impl_.status_.Set(from._internal_status(), 
+      _this->GetArenaForAllocation());
+  }
+  _impl_.payment_method_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.payment_method_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (!from._internal_payment_method().empty()) {
+    _this->_impl_.payment_method_.Set(from._internal_payment_method(), 
+      _this->GetArenaForAllocation());
+  }
+  _impl_.reservation_time_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.reservation_time_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (!from._internal_reservation_time().empty()) {
+    _this->_impl_.reservation_time_.Set(from._internal_reservation_time(), 
+      _this->GetArenaForAllocation());
+  }
+  _impl_.price_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.price_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (!from._internal_price().empty()) {
+    _this->_impl_.price_.Set(from._internal_price(), 
+      _this->GetArenaForAllocation());
+  }
+  _this->_impl_.timestamp_ = from._impl_.timestamp_;
+  // @@protoc_insertion_point(copy_constructor:events.Event)
+}
+
+inline void Event::SharedCtor(
+    ::_pb::Arena* arena, bool is_message_owned) {
+  (void)arena;
+  (void)is_message_owned;
+  new (&_impl_) Impl_{
+      decltype(_impl_.flight_id_){}
+    , decltype(_impl_.seat_){}
+    , decltype(_impl_.user_id_){}
+    , decltype(_impl_.customer_name_){}
+    , decltype(_impl_.status_){}
+    , decltype(_impl_.payment_method_){}
+    , decltype(_impl_.reservation_time_){}
+    , decltype(_impl_.price_){}
+    , decltype(_impl_.timestamp_){int64_t{0}}
+    , /*decltype(_impl_._cached_size_)*/{}
+  };
+  _impl_.flight_id_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.flight_id_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  _impl_.seat_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.seat_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  _impl_.user_id_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.user_id_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  _impl_.customer_name_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.customer_name_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  _impl_.status_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.status_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  _impl_.payment_method_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.payment_method_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  _impl_.reservation_time_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.reservation_time_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  _impl_.price_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.price_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+}
+
+Event::~Event() {
+  // @@protoc_insertion_point(destructor:events.Event)
+  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
+  (void)arena;
+    return;
+  }
+  SharedDtor();
+}
+
+inline void Event::SharedDtor() {
+  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
+  _impl_.flight_id_.Destroy();
+  _impl_.seat_.Destroy();
+  _impl_.user_id_.Destroy();
+  _impl_.customer_name_.Destroy();
+  _impl_.status_.Destroy();
+  _impl_.payment_method_.Destroy();
+  _impl_.reservation_time_.Destroy();
+  _impl_.price_.Destroy();
+}
+
+void Event::SetCachedSize(int size) const {
+  _impl_._cached_size_.Set(size);
+}
+
+void Event::Clear() {
+// @@protoc_insertion_point(message_clear_start:events.Event)
+  uint32_t cached_has_bits = 0;
+  // Prevent compiler warnings about cached_has_bits being unused
+  (void) cached_has_bits;
+
+  _impl_.flight_id_.ClearToEmpty();
+  _impl_.seat_.ClearToEmpty();
+  _impl_.user_id_.ClearToEmpty();
+  _impl_.customer_name_.ClearToEmpty();
+  _impl_.status_.ClearToEmpty();
+  _impl_.payment_method_.ClearToEmpty();
+  _impl_.reservation_time_.ClearToEmpty();
+  _impl_.price_.ClearToEmpty();
+  _impl_.timestamp_ = int64_t{0};
+  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
+}
+
+const char* Event::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
+#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
+  while (!ctx->Done(&ptr)) {
+    uint32_t tag;
+    ptr = ::_pbi::ReadTag(ptr, &tag);
+    switch (tag >> 3) {
+      // string flight_id = 1;
+      case 1:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
+          auto str = _internal_mutable_flight_id();
+          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
+          CHK_(ptr);
+          CHK_(::_pbi::VerifyUTF8(str, "events.Event.flight_id"));
+        } else
+          goto handle_unusual;
+        continue;
+      // string seat = 2;
+      case 2:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
+          auto str = _internal_mutable_seat();
+          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
+          CHK_(ptr);
+          CHK_(::_pbi::VerifyUTF8(str, "events.Event.seat"));
+        } else
+          goto handle_unusual;
+        continue;
+      // string user_id = 3;
+      case 3:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
+          auto str = _internal_mutable_user_id();
+          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
+          CHK_(ptr);
+          CHK_(::_pbi::VerifyUTF8(str, "events.Event.user_id"));
+        } else
+          goto handle_unusual;
+        continue;
+      // string customer_name = 4;
+      case 4:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
+          auto str = _internal_mutable_customer_name();
+          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
+          CHK_(ptr);
+          CHK_(::_pbi::VerifyUTF8(str, "events.Event.customer_name"));
+        } else
+          goto handle_unusual;
+        continue;
+      // string status = 5;
+      case 5:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 42)) {
+          auto str = _internal_mutable_status();
+          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
+          CHK_(ptr);
+          CHK_(::_pbi::VerifyUTF8(str, "events.Event.status"));
+        } else
+          goto handle_unusual;
+        continue;
+      // string payment_method = 6;
+      case 6:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
+          auto str = _internal_mutable_payment_method();
+          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
+          CHK_(ptr);
+          CHK_(::_pbi::VerifyUTF8(str, "events.Event.payment_method"));
+        } else
+          goto handle_unusual;
+        continue;
+      // string reservation_time = 7;
+      case 7:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 58)) {
+          auto str = _internal_mutable_reservation_time();
+          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
+          CHK_(ptr);
+          CHK_(::_pbi::VerifyUTF8(str, "events.Event.reservation_time"));
+        } else
+          goto handle_unusual;
+        continue;
+      // string price = 8;
+      case 8:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 66)) {
+          auto str = _internal_mutable_price();
+          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
+          CHK_(ptr);
+          CHK_(::_pbi::VerifyUTF8(str, "events.Event.price"));
+        } else
+          goto handle_unusual;
+        continue;
+      // int64 timestamp = 9;
+      case 9:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 72)) {
+          _impl_.timestamp_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
+          CHK_(ptr);
+        } else
+          goto handle_unusual;
+        continue;
+      default:
+        goto handle_unusual;
+    }  // switch
+  handle_unusual:
+    if ((tag == 0) || ((tag & 7) == 4)) {
+      CHK_(ptr);
+      ctx->SetLastTag(tag);
+      goto message_done;
+    }
+    ptr = UnknownFieldParse(
+        tag,
+        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
+        ptr, ctx);
+    CHK_(ptr != nullptr);
+  }  // while
+message_done:
+  return ptr;
+failure:
+  ptr = nullptr;
+  goto message_done;
+#undef CHK_
+}
+
+uint8_t* Event::_InternalSerialize(
+    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
+  // @@protoc_insertion_point(serialize_to_array_start:events.Event)
+  uint32_t cached_has_bits = 0;
+  (void) cached_has_bits;
+
+  // string flight_id = 1;
+  if (!this->_internal_flight_id().empty()) {
+    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
+      this->_internal_flight_id().data(), static_cast<int>(this->_internal_flight_id().length()),
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
+      "events.Event.flight_id");
+    target = stream->WriteStringMaybeAliased(
+        1, this->_internal_flight_id(), target);
+  }
+
+  // string seat = 2;
+  if (!this->_internal_seat().empty()) {
+    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
+      this->_internal_seat().data(), static_cast<int>(this->_internal_seat().length()),
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
+      "events.Event.seat");
+    target = stream->WriteStringMaybeAliased(
+        2, this->_internal_seat(), target);
+  }
+
+  // string user_id = 3;
+  if (!this->_internal_user_id().empty()) {
+    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
+      this->_internal_user_id().data(), static_cast<int>(this->_internal_user_id().length()),
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
+      "events.Event.user_id");
+    target = stream->WriteStringMaybeAliased(
+        3, this->_internal_user_id(), target);
+  }
+
+  // string customer_name = 4;
+  if (!this->_internal_customer_name().empty()) {
+    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
+      this->_internal_customer_name().data(), static_cast<int>(this->_internal_customer_name().length()),
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
+      "events.Event.customer_name");
+    target = stream->WriteStringMaybeAliased(
+        4, this->_internal_customer_name(), target);
+  }
+
+  // string status = 5;
+  if (!this->_internal_status().empty()) {
+    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
+      this->_internal_status().data(), static_cast<int>(this->_internal_status().length()),
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
+      "events.Event.status");
+    target = stream->WriteStringMaybeAliased(
+        5, this->_internal_status(), target);
+  }
+
+  // string payment_method = 6;
+  if (!this->_internal_payment_method().empty()) {
+    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
+      this->_internal_payment_method().data(), static_cast<int>(this->_internal_payment_method().length()),
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
+      "events.Event.payment_method");
+    target = stream->WriteStringMaybeAliased(
+        6, this->_internal_payment_method(), target);
+  }
+
+  // string reservation_time = 7;
+  if (!this->_internal_reservation_time().empty()) {
+    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
+      this->_internal_reservation_time().data(), static_cast<int>(this->_internal_reservation_time().length()),
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
+      "events.Event.reservation_time");
+    target = stream->WriteStringMaybeAliased(
+        7, this->_internal_reservation_time(), target);
+  }
+
+  // string price = 8;
+  if (!this->_internal_price().empty()) {
+    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
+      this->_internal_price().data(), static_cast<int>(this->_internal_price().length()),
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
+      "events.Event.price");
+    target = stream->WriteStringMaybeAliased(
+        8, this->_internal_price(), target);
+  }
+
+  // int64 timestamp = 9;
+  if (this->_internal_timestamp() != 0) {
+    target = stream->EnsureSpace(target);
+    target = ::_pbi::WireFormatLite::WriteInt64ToArray(9, this->_internal_timestamp(), target);
+  }
+
+  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
+    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
+        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
+  }
+  // @@protoc_insertion_point(serialize_to_array_end:events.Event)
+  return target;
+}
+
+size_t Event::ByteSizeLong() const {
+// @@protoc_insertion_point(message_byte_size_start:events.Event)
+  size_t total_size = 0;
+
+  uint32_t cached_has_bits = 0;
+  // Prevent compiler warnings about cached_has_bits being unused
+  (void) cached_has_bits;
+
+  // string flight_id = 1;
+  if (!this->_internal_flight_id().empty()) {
+    total_size += 1 +
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
+        this->_internal_flight_id());
+  }
+
+  // string seat = 2;
+  if (!this->_internal_seat().empty()) {
+    total_size += 1 +
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
+        this->_internal_seat());
+  }
+
+  // string user_id = 3;
+  if (!this->_internal_user_id().empty()) {
+    total_size += 1 +
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
+        this->_internal_user_id());
+  }
+
+  // string customer_name = 4;
+  if (!this->_internal_customer_name().empty()) {
+    total_size += 1 +
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
+        this->_internal_customer_name());
+  }
+
+  // string status = 5;
+  if (!this->_internal_status().empty()) {
+    total_size += 1 +
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
+        this->_internal_status());
+  }
+
+  // string payment_method = 6;
+  if (!this->_internal_payment_method().empty()) {
+    total_size += 1 +
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
+        this->_internal_payment_method());
+  }
+
+  // string reservation_time = 7;
+  if (!this->_internal_reservation_time().empty()) {
+    total_size += 1 +
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
+        this->_internal_reservation_time());
+  }
+
+  // string price = 8;
+  if (!this->_internal_price().empty()) {
+    total_size += 1 +
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
+        this->_internal_price());
+  }
+
+  // int64 timestamp = 9;
+  if (this->_internal_timestamp() != 0) {
+    total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_timestamp());
+  }
+
+  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
+}
+
+const ::PROTOBUF_NAMESPACE_ID::Message::ClassData Event::_class_data_ = {
+    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
+    Event::MergeImpl
+};
+const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*Event::GetClassData() const { return &_class_data_; }
+
+
+void Event::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
+  auto* const _this = static_cast<Event*>(&to_msg);
+  auto& from = static_cast<const Event&>(from_msg);
+  // @@protoc_insertion_point(class_specific_merge_from_start:events.Event)
+  GOOGLE_DCHECK_NE(&from, _this);
+  uint32_t cached_has_bits = 0;
+  (void) cached_has_bits;
+
+  if (!from._internal_flight_id().empty()) {
+    _this->_internal_set_flight_id(from._internal_flight_id());
+  }
+  if (!from._internal_seat().empty()) {
+    _this->_internal_set_seat(from._internal_seat());
+  }
+  if (!from._internal_user_id().empty()) {
+    _this->_internal_set_user_id(from._internal_user_id());
+  }
+  if (!from._internal_customer_name().empty()) {
+    _this->_internal_set_customer_name(from._internal_customer_name());
+  }
+  if (!from._internal_status().empty()) {
+    _this->_internal_set_status(from._internal_status());
+  }
+  if (!from._internal_payment_method().empty()) {
+    _this->_internal_set_payment_method(from._internal_payment_method());
+  }
+  if (!from._internal_reservation_time().empty()) {
+    _this->_internal_set_reservation_time(from._internal_reservation_time());
+  }
+  if (!from._internal_price().empty()) {
+    _this->_internal_set_price(from._internal_price());
+  }
+  if (from._internal_timestamp() != 0) {
+    _this->_internal_set_timestamp(from._internal_timestamp());
+  }
+  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
+}
+
+void Event::CopyFrom(const Event& from) {
+// @@protoc_insertion_point(class_specific_copy_from_start:events.Event)
+  if (&from == this) return;
+  Clear();
+  MergeFrom(from);
+}
+
+bool Event::IsInitialized() const {
+  return true;
+}
+
+void Event::InternalSwap(Event* other) {
+  using std::swap;
+  auto* lhs_arena = GetArenaForAllocation();
+  auto* rhs_arena = other->GetArenaForAllocation();
+  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
+  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
+      &_impl_.flight_id_, lhs_arena,
+      &other->_impl_.flight_id_, rhs_arena
+  );
+  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
+      &_impl_.seat_, lhs_arena,
+      &other->_impl_.seat_, rhs_arena
+  );
+  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
+      &_impl_.user_id_, lhs_arena,
+      &other->_impl_.user_id_, rhs_arena
+  );
+  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
+      &_impl_.customer_name_, lhs_arena,
+      &other->_impl_.customer_name_, rhs_arena
+  );
+  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
+      &_impl_.status_, lhs_arena,
+      &other->_impl_.status_, rhs_arena
+  );
+  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
+      &_impl_.payment_method_, lhs_arena,
+      &other->_impl_.payment_method_, rhs_arena
+  );
+  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
+      &_impl_.reservation_time_, lhs_arena,
+      &other->_impl_.reservation_time_, rhs_arena
+  );
+  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
+      &_impl_.price_, lhs_arena,
+      &other->_impl_.price_, rhs_arena
+  );
+  swap(_impl_.timestamp_, other->_impl_.timestamp_);
+}
+
+::PROTOBUF_NAMESPACE_ID::Metadata Event::GetMetadata() const {
+  return ::_pbi::AssignDescriptors(
+      &descriptor_table_event_2eproto_getter, &descriptor_table_event_2eproto_once,
+      file_level_metadata_event_2eproto[0]);
+}
+
+// ===================================================================
+
+class Ack::_Internal {
+ public:
+};
+
+Ack::Ack(::PROTOBUF_NAMESPACE_ID::Arena* arena,
+                         bool is_message_owned)
+  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
+  SharedCtor(arena, is_message_owned);
+  // @@protoc_insertion_point(arena_constructor:events.Ack)
+}
+Ack::Ack(const Ack& from)
+  : ::PROTOBUF_NAMESPACE_ID::Message() {
+  Ack* const _this = this; (void)_this;
+  new (&_impl_) Impl_{
+      decltype(_impl_.message_){}
+    , /*decltype(_impl_._cached_size_)*/{}};
+
+  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
+  _impl_.message_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.message_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (!from._internal_message().empty()) {
+    _this->_impl_.message_.Set(from._internal_message(), 
+      _this->GetArenaForAllocation());
+  }
+  // @@protoc_insertion_point(copy_constructor:events.Ack)
+}
+
+inline void Ack::SharedCtor(
+    ::_pb::Arena* arena, bool is_message_owned) {
+  (void)arena;
+  (void)is_message_owned;
+  new (&_impl_) Impl_{
+      decltype(_impl_.message_){}
+    , /*decltype(_impl_._cached_size_)*/{}
+  };
+  _impl_.message_.InitDefault();
+  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+    _impl_.message_.Set("", GetArenaForAllocation());
+  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+}
+
+Ack::~Ack() {
+  // @@protoc_insertion_point(destructor:events.Ack)
+  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
+  (void)arena;
+    return;
+  }
+  SharedDtor();
+}
+
+inline void Ack::SharedDtor() {
+  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
+  _impl_.message_.Destroy();
+}
+
+void Ack::SetCachedSize(int size) const {
+  _impl_._cached_size_.Set(size);
+}
+
+void Ack::Clear() {
+// @@protoc_insertion_point(message_clear_start:events.Ack)
+  uint32_t cached_has_bits = 0;
+  // Prevent compiler warnings about cached_has_bits being unused
+  (void) cached_has_bits;
+
+  _impl_.message_.ClearToEmpty();
+  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
+}
+
+const char* Ack::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
+#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
+  while (!ctx->Done(&ptr)) {
+    uint32_t tag;
+    ptr = ::_pbi::ReadTag(ptr, &tag);
+    switch (tag >> 3) {
+      // string message = 1;
+      case 1:
+        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
+          auto str = _internal_mutable_message();
+          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
+          CHK_(ptr);
+          CHK_(::_pbi::VerifyUTF8(str, "events.Ack.message"));
+        } else
+          goto handle_unusual;
+        continue;
+      default:
+        goto handle_unusual;
+    }  // switch
+  handle_unusual:
+    if ((tag == 0) || ((tag & 7) == 4)) {
+      CHK_(ptr);
+      ctx->SetLastTag(tag);
+      goto message_done;
+    }
+    ptr = UnknownFieldParse(
+        tag,
+        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
+        ptr, ctx);
+    CHK_(ptr != nullptr);
+  }  // while
+message_done:
+  return ptr;
+failure:
+  ptr = nullptr;
+  goto message_done;
+#undef CHK_
+}
+
+uint8_t* Ack::_InternalSerialize(
+    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
+  // @@protoc_insertion_point(serialize_to_array_start:events.Ack)
+  uint32_t cached_has_bits = 0;
+  (void) cached_has_bits;
+
+  // string message = 1;
+  if (!this->_internal_message().empty()) {
+    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
+      this->_internal_message().data(), static_cast<int>(this->_internal_message().length()),
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
+      "events.Ack.message");
+    target = stream->WriteStringMaybeAliased(
+        1, this->_internal_message(), target);
+  }
+
+  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
+    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
+        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
+  }
+  // @@protoc_insertion_point(serialize_to_array_end:events.Ack)
+  return target;
+}
+
+size_t Ack::ByteSizeLong() const {
+// @@protoc_insertion_point(message_byte_size_start:events.Ack)
+  size_t total_size = 0;
+
+  uint32_t cached_has_bits = 0;
+  // Prevent compiler warnings about cached_has_bits being unused
+  (void) cached_has_bits;
+
+  // string message = 1;
+  if (!this->_internal_message().empty()) {
+    total_size += 1 +
+      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
+        this->_internal_message());
+  }
+
+  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
+}
+
+const ::PROTOBUF_NAMESPACE_ID::Message::ClassData Ack::_class_data_ = {
+    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
+    Ack::MergeImpl
+};
+const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*Ack::GetClassData() const { return &_class_data_; }
+
+
+void Ack::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
+  auto* const _this = static_cast<Ack*>(&to_msg);
+  auto& from = static_cast<const Ack&>(from_msg);
+  // @@protoc_insertion_point(class_specific_merge_from_start:events.Ack)
+  GOOGLE_DCHECK_NE(&from, _this);
+  uint32_t cached_has_bits = 0;
+  (void) cached_has_bits;
+
+  if (!from._internal_message().empty()) {
+    _this->_internal_set_message(from._internal_message());
+  }
+  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
+}
+
+void Ack::CopyFrom(const Ack& from) {
+// @@protoc_insertion_point(class_specific_copy_from_start:events.Ack)
+  if (&from == this) return;
+  Clear();
+  MergeFrom(from);
+}
+
+bool Ack::IsInitialized() const {
+  return true;
+}
+
+void Ack::InternalSwap(Ack* other) {
+  using std::swap;
+  auto* lhs_arena = GetArenaForAllocation();
+  auto* rhs_arena = other->GetArenaForAllocation();
+  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
+  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
+      &_impl_.message_, lhs_arena,
+      &other->_impl_.message_, rhs_arena
+  );
+}
+
+::PROTOBUF_NAMESPACE_ID::Metadata Ack::GetMetadata() const {
+  return ::_pbi::AssignDescriptors(
+      &descriptor_table_event_2eproto_getter, &descriptor_table_event_2eproto_once,
+      file_level_metadata_event_2eproto[1]);
+}
+
+// @@protoc_insertion_point(namespace_scope)
+}  // namespace events
+PROTOBUF_NAMESPACE_OPEN
+template<> PROTOBUF_NOINLINE ::events::Event*
+Arena::CreateMaybeMessage< ::events::Event >(Arena* arena) {
+  return Arena::CreateMessageInternal< ::events::Event >(arena);
+}
+template<> PROTOBUF_NOINLINE ::events::Ack*
+Arena::CreateMaybeMessage< ::events::Ack >(Arena* arena) {
+  return Arena::CreateMessageInternal< ::events::Ack >(arena);
+}
+PROTOBUF_NAMESPACE_CLOSE
+
+// @@protoc_insertion_point(global_scope)
+#include <google/protobuf/port_undef.inc>
diff --git a/grpc/event.pb.h b/grpc/event.pb.h
new file mode 100644
index 0000000..bb39e98
--- /dev/null
+++ b/grpc/event.pb.h
@@ -0,0 +1,988 @@
+// Generated by the protocol buffer compiler.  DO NOT EDIT!
+// source: event.proto
+
+#ifndef GOOGLE_PROTOBUF_INCLUDED_event_2eproto
+#define GOOGLE_PROTOBUF_INCLUDED_event_2eproto
+
+#include <limits>
+#include <string>
+
+#include <google/protobuf/port_def.inc>
+#if PROTOBUF_VERSION < 3021000
+#error This file was generated by a newer version of protoc which is
+#error incompatible with your Protocol Buffer headers. Please update
+#error your headers.
+#endif
+#if 3021012 < PROTOBUF_MIN_PROTOC_VERSION
+#error This file was generated by an older version of protoc which is
+#error incompatible with your Protocol Buffer headers. Please
+#error regenerate this file with a newer version of protoc.
+#endif
+
+#include <google/protobuf/port_undef.inc>
+#include <google/protobuf/io/coded_stream.h>
+#include <google/protobuf/arena.h>
+#include <google/protobuf/arenastring.h>
+#include <google/protobuf/generated_message_util.h>
+#include <google/protobuf/metadata_lite.h>
+#include <google/protobuf/generated_message_reflection.h>
+#include <google/protobuf/message.h>
+#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
+#include <google/protobuf/extension_set.h>  // IWYU pragma: export
+#include <google/protobuf/unknown_field_set.h>
+// @@protoc_insertion_point(includes)
+#include <google/protobuf/port_def.inc>
+#define PROTOBUF_INTERNAL_EXPORT_event_2eproto
+PROTOBUF_NAMESPACE_OPEN
+namespace internal {
+class AnyMetadata;
+}  // namespace internal
+PROTOBUF_NAMESPACE_CLOSE
+
+// Internal implementation detail -- do not use these members.
+struct TableStruct_event_2eproto {
+  static const uint32_t offsets[];
+};
+extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_event_2eproto;
+namespace events {
+class Ack;
+struct AckDefaultTypeInternal;
+extern AckDefaultTypeInternal _Ack_default_instance_;
+class Event;
+struct EventDefaultTypeInternal;
+extern EventDefaultTypeInternal _Event_default_instance_;
+}  // namespace events
+PROTOBUF_NAMESPACE_OPEN
+template<> ::events::Ack* Arena::CreateMaybeMessage<::events::Ack>(Arena*);
+template<> ::events::Event* Arena::CreateMaybeMessage<::events::Event>(Arena*);
+PROTOBUF_NAMESPACE_CLOSE
+namespace events {
+
+// ===================================================================
+
+class Event final :
+    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:events.Event) */ {
+ public:
+  inline Event() : Event(nullptr) {}
+  ~Event() override;
+  explicit PROTOBUF_CONSTEXPR Event(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
+
+  Event(const Event& from);
+  Event(Event&& from) noexcept
+    : Event() {
+    *this = ::std::move(from);
+  }
+
+  inline Event& operator=(const Event& from) {
+    CopyFrom(from);
+    return *this;
+  }
+  inline Event& operator=(Event&& from) noexcept {
+    if (this == &from) return *this;
+    if (GetOwningArena() == from.GetOwningArena()
+  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
+        && GetOwningArena() != nullptr
+  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
+    ) {
+      InternalSwap(&from);
+    } else {
+      CopyFrom(from);
+    }
+    return *this;
+  }
+
+  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
+    return GetDescriptor();
+  }
+  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
+    return default_instance().GetMetadata().descriptor;
+  }
+  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
+    return default_instance().GetMetadata().reflection;
+  }
+  static const Event& default_instance() {
+    return *internal_default_instance();
+  }
+  static inline const Event* internal_default_instance() {
+    return reinterpret_cast<const Event*>(
+               &_Event_default_instance_);
+  }
+  static constexpr int kIndexInFileMessages =
+    0;
+
+  friend void swap(Event& a, Event& b) {
+    a.Swap(&b);
+  }
+  inline void Swap(Event* other) {
+    if (other == this) return;
+  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
+    if (GetOwningArena() != nullptr &&
+        GetOwningArena() == other->GetOwningArena()) {
+   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
+    if (GetOwningArena() == other->GetOwningArena()) {
+  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
+      InternalSwap(other);
+    } else {
+      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
+    }
+  }
+  void UnsafeArenaSwap(Event* other) {
+    if (other == this) return;
+    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
+    InternalSwap(other);
+  }
+
+  // implements Message ----------------------------------------------
+
+  Event* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
+    return CreateMaybeMessage<Event>(arena);
+  }
+  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
+  void CopyFrom(const Event& from);
+  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
+  void MergeFrom( const Event& from) {
+    Event::MergeImpl(*this, from);
+  }
+  private:
+  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
+  public:
+  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
+  bool IsInitialized() const final;
+
+  size_t ByteSizeLong() const final;
+  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
+  uint8_t* _InternalSerialize(
+      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
+  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }
+
+  private:
+  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
+  void SharedDtor();
+  void SetCachedSize(int size) const final;
+  void InternalSwap(Event* other);
+
+  private:
+  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
+  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
+    return "events.Event";
+  }
+  protected:
+  explicit Event(::PROTOBUF_NAMESPACE_ID::Arena* arena,
+                       bool is_message_owned = false);
+  public:
+
+  static const ClassData _class_data_;
+  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;
+
+  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
+
+  // nested types ----------------------------------------------------
+
+  // accessors -------------------------------------------------------
+
+  enum : int {
+    kFlightIdFieldNumber = 1,
+    kSeatFieldNumber = 2,
+    kUserIdFieldNumber = 3,
+    kCustomerNameFieldNumber = 4,
+    kStatusFieldNumber = 5,
+    kPaymentMethodFieldNumber = 6,
+    kReservationTimeFieldNumber = 7,
+    kPriceFieldNumber = 8,
+    kTimestampFieldNumber = 9,
+  };
+  // string flight_id = 1;
+  void clear_flight_id();
+  const std::string& flight_id() const;
+  template <typename ArgT0 = const std::string&, typename... ArgT>
+  void set_flight_id(ArgT0&& arg0, ArgT... args);
+  std::string* mutable_flight_id();
+  PROTOBUF_NODISCARD std::string* release_flight_id();
+  void set_allocated_flight_id(std::string* flight_id);
+  private:
+  const std::string& _internal_flight_id() const;
+  inline PROTOBUF_ALWAYS_INLINE void _internal_set_flight_id(const std::string& value);
+  std::string* _internal_mutable_flight_id();
+  public:
+
+  // string seat = 2;
+  void clear_seat();
+  const std::string& seat() const;
+  template <typename ArgT0 = const std::string&, typename... ArgT>
+  void set_seat(ArgT0&& arg0, ArgT... args);
+  std::string* mutable_seat();
+  PROTOBUF_NODISCARD std::string* release_seat();
+  void set_allocated_seat(std::string* seat);
+  private:
+  const std::string& _internal_seat() const;
+  inline PROTOBUF_ALWAYS_INLINE void _internal_set_seat(const std::string& value);
+  std::string* _internal_mutable_seat();
+  public:
+
+  // string user_id = 3;
+  void clear_user_id();
+  const std::string& user_id() const;
+  template <typename ArgT0 = const std::string&, typename... ArgT>
+  void set_user_id(ArgT0&& arg0, ArgT... args);
+  std::string* mutable_user_id();
+  PROTOBUF_NODISCARD std::string* release_user_id();
+  void set_allocated_user_id(std::string* user_id);
+  private:
+  const std::string& _internal_user_id() const;
+  inline PROTOBUF_ALWAYS_INLINE void _internal_set_user_id(const std::string& value);
+  std::string* _internal_mutable_user_id();
+  public:
+
+  // string customer_name = 4;
+  void clear_customer_name();
+  const std::string& customer_name() const;
+  template <typename ArgT0 = const std::string&, typename... ArgT>
+  void set_customer_name(ArgT0&& arg0, ArgT... args);
+  std::string* mutable_customer_name();
+  PROTOBUF_NODISCARD std::string* release_customer_name();
+  void set_allocated_customer_name(std::string* customer_name);
+  private:
+  const std::string& _internal_customer_name() const;
+  inline PROTOBUF_ALWAYS_INLINE void _internal_set_customer_name(const std::string& value);
+  std::string* _internal_mutable_customer_name();
+  public:
+
+  // string status = 5;
+  void clear_status();
+  const std::string& status() const;
+  template <typename ArgT0 = const std::string&, typename... ArgT>
+  void set_status(ArgT0&& arg0, ArgT... args);
+  std::string* mutable_status();
+  PROTOBUF_NODISCARD std::string* release_status();
+  void set_allocated_status(std::string* status);
+  private:
+  const std::string& _internal_status() const;
+  inline PROTOBUF_ALWAYS_INLINE void _internal_set_status(const std::string& value);
+  std::string* _internal_mutable_status();
+  public:
+
+  // string payment_method = 6;
+  void clear_payment_method();
+  const std::string& payment_method() const;
+  template <typename ArgT0 = const std::string&, typename... ArgT>
+  void set_payment_method(ArgT0&& arg0, ArgT... args);
+  std::string* mutable_payment_method();
+  PROTOBUF_NODISCARD std::string* release_payment_method();
+  void set_allocated_payment_method(std::string* payment_method);
+  private:
+  const std::string& _internal_payment_method() const;
+  inline PROTOBUF_ALWAYS_INLINE void _internal_set_payment_method(const std::string& value);
+  std::string* _internal_mutable_payment_method();
+  public:
+
+  // string reservation_time = 7;
+  void clear_reservation_time();
+  const std::string& reservation_time() const;
+  template <typename ArgT0 = const std::string&, typename... ArgT>
+  void set_reservation_time(ArgT0&& arg0, ArgT... args);
+  std::string* mutable_reservation_time();
+  PROTOBUF_NODISCARD std::string* release_reservation_time();
+  void set_allocated_reservation_time(std::string* reservation_time);
+  private:
+  const std::string& _internal_reservation_time() const;
+  inline PROTOBUF_ALWAYS_INLINE void _internal_set_reservation_time(const std::string& value);
+  std::string* _internal_mutable_reservation_time();
+  public:
+
+  // string price = 8;
+  void clear_price();
+  const std::string& price() const;
+  template <typename ArgT0 = const std::string&, typename... ArgT>
+  void set_price(ArgT0&& arg0, ArgT... args);
+  std::string* mutable_price();
+  PROTOBUF_NODISCARD std::string* release_price();
+  void set_allocated_price(std::string* price);
+  private:
+  const std::string& _internal_price() const;
+  inline PROTOBUF_ALWAYS_INLINE void _internal_set_price(const std::string& value);
+  std::string* _internal_mutable_price();
+  public:
+
+  // int64 timestamp = 9;
+  void clear_timestamp();
+  int64_t timestamp() const;
+  void set_timestamp(int64_t value);
+  private:
+  int64_t _internal_timestamp() const;
+  void _internal_set_timestamp(int64_t value);
+  public:
+
+  // @@protoc_insertion_point(class_scope:events.Event)
+ private:
+  class _Internal;
+
+  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
+  typedef void InternalArenaConstructable_;
+  typedef void DestructorSkippable_;
+  struct Impl_ {
+    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr flight_id_;
+    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr seat_;
+    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr user_id_;
+    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr customer_name_;
+    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr status_;
+    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr payment_method_;
+    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr reservation_time_;
+    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr price_;
+    int64_t timestamp_;
+    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
+  };
+  union { Impl_ _impl_; };
+  friend struct ::TableStruct_event_2eproto;
+};
+// -------------------------------------------------------------------
+
+class Ack final :
+    public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:events.Ack) */ {
+ public:
+  inline Ack() : Ack(nullptr) {}
+  ~Ack() override;
+  explicit PROTOBUF_CONSTEXPR Ack(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);
+
+  Ack(const Ack& from);
+  Ack(Ack&& from) noexcept
+    : Ack() {
+    *this = ::std::move(from);
+  }
+
+  inline Ack& operator=(const Ack& from) {
+    CopyFrom(from);
+    return *this;
+  }
+  inline Ack& operator=(Ack&& from) noexcept {
+    if (this == &from) return *this;
+    if (GetOwningArena() == from.GetOwningArena()
+  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
+        && GetOwningArena() != nullptr
+  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
+    ) {
+      InternalSwap(&from);
+    } else {
+      CopyFrom(from);
+    }
+    return *this;
+  }
+
+  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() {
+    return GetDescriptor();
+  }
+  static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() {
+    return default_instance().GetMetadata().descriptor;
+  }
+  static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() {
+    return default_instance().GetMetadata().reflection;
+  }
+  static const Ack& default_instance() {
+    return *internal_default_instance();
+  }
+  static inline const Ack* internal_default_instance() {
+    return reinterpret_cast<const Ack*>(
+               &_Ack_default_instance_);
+  }
+  static constexpr int kIndexInFileMessages =
+    1;
+
+  friend void swap(Ack& a, Ack& b) {
+    a.Swap(&b);
+  }
+  inline void Swap(Ack* other) {
+    if (other == this) return;
+  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
+    if (GetOwningArena() != nullptr &&
+        GetOwningArena() == other->GetOwningArena()) {
+   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
+    if (GetOwningArena() == other->GetOwningArena()) {
+  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
+      InternalSwap(other);
+    } else {
+      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
+    }
+  }
+  void UnsafeArenaSwap(Ack* other) {
+    if (other == this) return;
+    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
+    InternalSwap(other);
+  }
+
+  // implements Message ----------------------------------------------
+
+  Ack* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
+    return CreateMaybeMessage<Ack>(arena);
+  }
+  using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom;
+  void CopyFrom(const Ack& from);
+  using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom;
+  void MergeFrom( const Ack& from) {
+    Ack::MergeImpl(*this, from);
+  }
+  private:
+  static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg);
+  public:
+  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
+  bool IsInitialized() const final;
+
+  size_t ByteSizeLong() const final;
+  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
+  uint8_t* _InternalSerialize(
+      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
+  int GetCachedSize() const final { return _impl_._cached_size_.Get(); }
+
+  private:
+  void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
+  void SharedDtor();
+  void SetCachedSize(int size) const final;
+  void InternalSwap(Ack* other);
+
+  private:
+  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
+  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
+    return "events.Ack";
+  }
+  protected:
+  explicit Ack(::PROTOBUF_NAMESPACE_ID::Arena* arena,
+                       bool is_message_owned = false);
+  public:
+
+  static const ClassData _class_data_;
+  const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final;
+
+  ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final;
+
+  // nested types ----------------------------------------------------
+
+  // accessors -------------------------------------------------------
+
+  enum : int {
+    kMessageFieldNumber = 1,
+  };
+  // string message = 1;
+  void clear_message();
+  const std::string& message() const;
+  template <typename ArgT0 = const std::string&, typename... ArgT>
+  void set_message(ArgT0&& arg0, ArgT... args);
+  std::string* mutable_message();
+  PROTOBUF_NODISCARD std::string* release_message();
+  void set_allocated_message(std::string* message);
+  private:
+  const std::string& _internal_message() const;
+  inline PROTOBUF_ALWAYS_INLINE void _internal_set_message(const std::string& value);
+  std::string* _internal_mutable_message();
+  public:
+
+  // @@protoc_insertion_point(class_scope:events.Ack)
+ private:
+  class _Internal;
+
+  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
+  typedef void InternalArenaConstructable_;
+  typedef void DestructorSkippable_;
+  struct Impl_ {
+    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr message_;
+    mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
+  };
+  union { Impl_ _impl_; };
+  friend struct ::TableStruct_event_2eproto;
+};
+// ===================================================================
+
+
+// ===================================================================
+
+#ifdef __GNUC__
+  #pragma GCC diagnostic push
+  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
+#endif  // __GNUC__
+// Event
+
+// string flight_id = 1;
+inline void Event::clear_flight_id() {
+  _impl_.flight_id_.ClearToEmpty();
+}
+inline const std::string& Event::flight_id() const {
+  // @@protoc_insertion_point(field_get:events.Event.flight_id)
+  return _internal_flight_id();
+}
+template <typename ArgT0, typename... ArgT>
+inline PROTOBUF_ALWAYS_INLINE
+void Event::set_flight_id(ArgT0&& arg0, ArgT... args) {
+ 
+ _impl_.flight_id_.Set(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
+  // @@protoc_insertion_point(field_set:events.Event.flight_id)
+}
+inline std::string* Event::mutable_flight_id() {
+  std::string* _s = _internal_mutable_flight_id();
+  // @@protoc_insertion_point(field_mutable:events.Event.flight_id)
+  return _s;
+}
+inline const std::string& Event::_internal_flight_id() const {
+  return _impl_.flight_id_.Get();
+}
+inline void Event::_internal_set_flight_id(const std::string& value) {
+  
+  _impl_.flight_id_.Set(value, GetArenaForAllocation());
+}
+inline std::string* Event::_internal_mutable_flight_id() {
+  
+  return _impl_.flight_id_.Mutable(GetArenaForAllocation());
+}
+inline std::string* Event::release_flight_id() {
+  // @@protoc_insertion_point(field_release:events.Event.flight_id)
+  return _impl_.flight_id_.Release();
+}
+inline void Event::set_allocated_flight_id(std::string* flight_id) {
+  if (flight_id != nullptr) {
+    
+  } else {
+    
+  }
+  _impl_.flight_id_.SetAllocated(flight_id, GetArenaForAllocation());
+#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (_impl_.flight_id_.IsDefault()) {
+    _impl_.flight_id_.Set("", GetArenaForAllocation());
+  }
+#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  // @@protoc_insertion_point(field_set_allocated:events.Event.flight_id)
+}
+
+// string seat = 2;
+inline void Event::clear_seat() {
+  _impl_.seat_.ClearToEmpty();
+}
+inline const std::string& Event::seat() const {
+  // @@protoc_insertion_point(field_get:events.Event.seat)
+  return _internal_seat();
+}
+template <typename ArgT0, typename... ArgT>
+inline PROTOBUF_ALWAYS_INLINE
+void Event::set_seat(ArgT0&& arg0, ArgT... args) {
+ 
+ _impl_.seat_.Set(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
+  // @@protoc_insertion_point(field_set:events.Event.seat)
+}
+inline std::string* Event::mutable_seat() {
+  std::string* _s = _internal_mutable_seat();
+  // @@protoc_insertion_point(field_mutable:events.Event.seat)
+  return _s;
+}
+inline const std::string& Event::_internal_seat() const {
+  return _impl_.seat_.Get();
+}
+inline void Event::_internal_set_seat(const std::string& value) {
+  
+  _impl_.seat_.Set(value, GetArenaForAllocation());
+}
+inline std::string* Event::_internal_mutable_seat() {
+  
+  return _impl_.seat_.Mutable(GetArenaForAllocation());
+}
+inline std::string* Event::release_seat() {
+  // @@protoc_insertion_point(field_release:events.Event.seat)
+  return _impl_.seat_.Release();
+}
+inline void Event::set_allocated_seat(std::string* seat) {
+  if (seat != nullptr) {
+    
+  } else {
+    
+  }
+  _impl_.seat_.SetAllocated(seat, GetArenaForAllocation());
+#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (_impl_.seat_.IsDefault()) {
+    _impl_.seat_.Set("", GetArenaForAllocation());
+  }
+#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  // @@protoc_insertion_point(field_set_allocated:events.Event.seat)
+}
+
+// string user_id = 3;
+inline void Event::clear_user_id() {
+  _impl_.user_id_.ClearToEmpty();
+}
+inline const std::string& Event::user_id() const {
+  // @@protoc_insertion_point(field_get:events.Event.user_id)
+  return _internal_user_id();
+}
+template <typename ArgT0, typename... ArgT>
+inline PROTOBUF_ALWAYS_INLINE
+void Event::set_user_id(ArgT0&& arg0, ArgT... args) {
+ 
+ _impl_.user_id_.Set(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
+  // @@protoc_insertion_point(field_set:events.Event.user_id)
+}
+inline std::string* Event::mutable_user_id() {
+  std::string* _s = _internal_mutable_user_id();
+  // @@protoc_insertion_point(field_mutable:events.Event.user_id)
+  return _s;
+}
+inline const std::string& Event::_internal_user_id() const {
+  return _impl_.user_id_.Get();
+}
+inline void Event::_internal_set_user_id(const std::string& value) {
+  
+  _impl_.user_id_.Set(value, GetArenaForAllocation());
+}
+inline std::string* Event::_internal_mutable_user_id() {
+  
+  return _impl_.user_id_.Mutable(GetArenaForAllocation());
+}
+inline std::string* Event::release_user_id() {
+  // @@protoc_insertion_point(field_release:events.Event.user_id)
+  return _impl_.user_id_.Release();
+}
+inline void Event::set_allocated_user_id(std::string* user_id) {
+  if (user_id != nullptr) {
+    
+  } else {
+    
+  }
+  _impl_.user_id_.SetAllocated(user_id, GetArenaForAllocation());
+#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (_impl_.user_id_.IsDefault()) {
+    _impl_.user_id_.Set("", GetArenaForAllocation());
+  }
+#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  // @@protoc_insertion_point(field_set_allocated:events.Event.user_id)
+}
+
+// string customer_name = 4;
+inline void Event::clear_customer_name() {
+  _impl_.customer_name_.ClearToEmpty();
+}
+inline const std::string& Event::customer_name() const {
+  // @@protoc_insertion_point(field_get:events.Event.customer_name)
+  return _internal_customer_name();
+}
+template <typename ArgT0, typename... ArgT>
+inline PROTOBUF_ALWAYS_INLINE
+void Event::set_customer_name(ArgT0&& arg0, ArgT... args) {
+ 
+ _impl_.customer_name_.Set(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
+  // @@protoc_insertion_point(field_set:events.Event.customer_name)
+}
+inline std::string* Event::mutable_customer_name() {
+  std::string* _s = _internal_mutable_customer_name();
+  // @@protoc_insertion_point(field_mutable:events.Event.customer_name)
+  return _s;
+}
+inline const std::string& Event::_internal_customer_name() const {
+  return _impl_.customer_name_.Get();
+}
+inline void Event::_internal_set_customer_name(const std::string& value) {
+  
+  _impl_.customer_name_.Set(value, GetArenaForAllocation());
+}
+inline std::string* Event::_internal_mutable_customer_name() {
+  
+  return _impl_.customer_name_.Mutable(GetArenaForAllocation());
+}
+inline std::string* Event::release_customer_name() {
+  // @@protoc_insertion_point(field_release:events.Event.customer_name)
+  return _impl_.customer_name_.Release();
+}
+inline void Event::set_allocated_customer_name(std::string* customer_name) {
+  if (customer_name != nullptr) {
+    
+  } else {
+    
+  }
+  _impl_.customer_name_.SetAllocated(customer_name, GetArenaForAllocation());
+#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (_impl_.customer_name_.IsDefault()) {
+    _impl_.customer_name_.Set("", GetArenaForAllocation());
+  }
+#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  // @@protoc_insertion_point(field_set_allocated:events.Event.customer_name)
+}
+
+// string status = 5;
+inline void Event::clear_status() {
+  _impl_.status_.ClearToEmpty();
+}
+inline const std::string& Event::status() const {
+  // @@protoc_insertion_point(field_get:events.Event.status)
+  return _internal_status();
+}
+template <typename ArgT0, typename... ArgT>
+inline PROTOBUF_ALWAYS_INLINE
+void Event::set_status(ArgT0&& arg0, ArgT... args) {
+ 
+ _impl_.status_.Set(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
+  // @@protoc_insertion_point(field_set:events.Event.status)
+}
+inline std::string* Event::mutable_status() {
+  std::string* _s = _internal_mutable_status();
+  // @@protoc_insertion_point(field_mutable:events.Event.status)
+  return _s;
+}
+inline const std::string& Event::_internal_status() const {
+  return _impl_.status_.Get();
+}
+inline void Event::_internal_set_status(const std::string& value) {
+  
+  _impl_.status_.Set(value, GetArenaForAllocation());
+}
+inline std::string* Event::_internal_mutable_status() {
+  
+  return _impl_.status_.Mutable(GetArenaForAllocation());
+}
+inline std::string* Event::release_status() {
+  // @@protoc_insertion_point(field_release:events.Event.status)
+  return _impl_.status_.Release();
+}
+inline void Event::set_allocated_status(std::string* status) {
+  if (status != nullptr) {
+    
+  } else {
+    
+  }
+  _impl_.status_.SetAllocated(status, GetArenaForAllocation());
+#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (_impl_.status_.IsDefault()) {
+    _impl_.status_.Set("", GetArenaForAllocation());
+  }
+#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  // @@protoc_insertion_point(field_set_allocated:events.Event.status)
+}
+
+// string payment_method = 6;
+inline void Event::clear_payment_method() {
+  _impl_.payment_method_.ClearToEmpty();
+}
+inline const std::string& Event::payment_method() const {
+  // @@protoc_insertion_point(field_get:events.Event.payment_method)
+  return _internal_payment_method();
+}
+template <typename ArgT0, typename... ArgT>
+inline PROTOBUF_ALWAYS_INLINE
+void Event::set_payment_method(ArgT0&& arg0, ArgT... args) {
+ 
+ _impl_.payment_method_.Set(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
+  // @@protoc_insertion_point(field_set:events.Event.payment_method)
+}
+inline std::string* Event::mutable_payment_method() {
+  std::string* _s = _internal_mutable_payment_method();
+  // @@protoc_insertion_point(field_mutable:events.Event.payment_method)
+  return _s;
+}
+inline const std::string& Event::_internal_payment_method() const {
+  return _impl_.payment_method_.Get();
+}
+inline void Event::_internal_set_payment_method(const std::string& value) {
+  
+  _impl_.payment_method_.Set(value, GetArenaForAllocation());
+}
+inline std::string* Event::_internal_mutable_payment_method() {
+  
+  return _impl_.payment_method_.Mutable(GetArenaForAllocation());
+}
+inline std::string* Event::release_payment_method() {
+  // @@protoc_insertion_point(field_release:events.Event.payment_method)
+  return _impl_.payment_method_.Release();
+}
+inline void Event::set_allocated_payment_method(std::string* payment_method) {
+  if (payment_method != nullptr) {
+    
+  } else {
+    
+  }
+  _impl_.payment_method_.SetAllocated(payment_method, GetArenaForAllocation());
+#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (_impl_.payment_method_.IsDefault()) {
+    _impl_.payment_method_.Set("", GetArenaForAllocation());
+  }
+#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  // @@protoc_insertion_point(field_set_allocated:events.Event.payment_method)
+}
+
+// string reservation_time = 7;
+inline void Event::clear_reservation_time() {
+  _impl_.reservation_time_.ClearToEmpty();
+}
+inline const std::string& Event::reservation_time() const {
+  // @@protoc_insertion_point(field_get:events.Event.reservation_time)
+  return _internal_reservation_time();
+}
+template <typename ArgT0, typename... ArgT>
+inline PROTOBUF_ALWAYS_INLINE
+void Event::set_reservation_time(ArgT0&& arg0, ArgT... args) {
+ 
+ _impl_.reservation_time_.Set(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
+  // @@protoc_insertion_point(field_set:events.Event.reservation_time)
+}
+inline std::string* Event::mutable_reservation_time() {
+  std::string* _s = _internal_mutable_reservation_time();
+  // @@protoc_insertion_point(field_mutable:events.Event.reservation_time)
+  return _s;
+}
+inline const std::string& Event::_internal_reservation_time() const {
+  return _impl_.reservation_time_.Get();
+}
+inline void Event::_internal_set_reservation_time(const std::string& value) {
+  
+  _impl_.reservation_time_.Set(value, GetArenaForAllocation());
+}
+inline std::string* Event::_internal_mutable_reservation_time() {
+  
+  return _impl_.reservation_time_.Mutable(GetArenaForAllocation());
+}
+inline std::string* Event::release_reservation_time() {
+  // @@protoc_insertion_point(field_release:events.Event.reservation_time)
+  return _impl_.reservation_time_.Release();
+}
+inline void Event::set_allocated_reservation_time(std::string* reservation_time) {
+  if (reservation_time != nullptr) {
+    
+  } else {
+    
+  }
+  _impl_.reservation_time_.SetAllocated(reservation_time, GetArenaForAllocation());
+#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (_impl_.reservation_time_.IsDefault()) {
+    _impl_.reservation_time_.Set("", GetArenaForAllocation());
+  }
+#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  // @@protoc_insertion_point(field_set_allocated:events.Event.reservation_time)
+}
+
+// string price = 8;
+inline void Event::clear_price() {
+  _impl_.price_.ClearToEmpty();
+}
+inline const std::string& Event::price() const {
+  // @@protoc_insertion_point(field_get:events.Event.price)
+  return _internal_price();
+}
+template <typename ArgT0, typename... ArgT>
+inline PROTOBUF_ALWAYS_INLINE
+void Event::set_price(ArgT0&& arg0, ArgT... args) {
+ 
+ _impl_.price_.Set(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
+  // @@protoc_insertion_point(field_set:events.Event.price)
+}
+inline std::string* Event::mutable_price() {
+  std::string* _s = _internal_mutable_price();
+  // @@protoc_insertion_point(field_mutable:events.Event.price)
+  return _s;
+}
+inline const std::string& Event::_internal_price() const {
+  return _impl_.price_.Get();
+}
+inline void Event::_internal_set_price(const std::string& value) {
+  
+  _impl_.price_.Set(value, GetArenaForAllocation());
+}
+inline std::string* Event::_internal_mutable_price() {
+  
+  return _impl_.price_.Mutable(GetArenaForAllocation());
+}
+inline std::string* Event::release_price() {
+  // @@protoc_insertion_point(field_release:events.Event.price)
+  return _impl_.price_.Release();
+}
+inline void Event::set_allocated_price(std::string* price) {
+  if (price != nullptr) {
+    
+  } else {
+    
+  }
+  _impl_.price_.SetAllocated(price, GetArenaForAllocation());
+#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (_impl_.price_.IsDefault()) {
+    _impl_.price_.Set("", GetArenaForAllocation());
+  }
+#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  // @@protoc_insertion_point(field_set_allocated:events.Event.price)
+}
+
+// int64 timestamp = 9;
+inline void Event::clear_timestamp() {
+  _impl_.timestamp_ = int64_t{0};
+}
+inline int64_t Event::_internal_timestamp() const {
+  return _impl_.timestamp_;
+}
+inline int64_t Event::timestamp() const {
+  // @@protoc_insertion_point(field_get:events.Event.timestamp)
+  return _internal_timestamp();
+}
+inline void Event::_internal_set_timestamp(int64_t value) {
+  
+  _impl_.timestamp_ = value;
+}
+inline void Event::set_timestamp(int64_t value) {
+  _internal_set_timestamp(value);
+  // @@protoc_insertion_point(field_set:events.Event.timestamp)
+}
+
+// -------------------------------------------------------------------
+
+// Ack
+
+// string message = 1;
+inline void Ack::clear_message() {
+  _impl_.message_.ClearToEmpty();
+}
+inline const std::string& Ack::message() const {
+  // @@protoc_insertion_point(field_get:events.Ack.message)
+  return _internal_message();
+}
+template <typename ArgT0, typename... ArgT>
+inline PROTOBUF_ALWAYS_INLINE
+void Ack::set_message(ArgT0&& arg0, ArgT... args) {
+ 
+ _impl_.message_.Set(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
+  // @@protoc_insertion_point(field_set:events.Ack.message)
+}
+inline std::string* Ack::mutable_message() {
+  std::string* _s = _internal_mutable_message();
+  // @@protoc_insertion_point(field_mutable:events.Ack.message)
+  return _s;
+}
+inline const std::string& Ack::_internal_message() const {
+  return _impl_.message_.Get();
+}
+inline void Ack::_internal_set_message(const std::string& value) {
+  
+  _impl_.message_.Set(value, GetArenaForAllocation());
+}
+inline std::string* Ack::_internal_mutable_message() {
+  
+  return _impl_.message_.Mutable(GetArenaForAllocation());
+}
+inline std::string* Ack::release_message() {
+  // @@protoc_insertion_point(field_release:events.Ack.message)
+  return _impl_.message_.Release();
+}
+inline void Ack::set_allocated_message(std::string* message) {
+  if (message != nullptr) {
+    
+  } else {
+    
+  }
+  _impl_.message_.SetAllocated(message, GetArenaForAllocation());
+#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  if (_impl_.message_.IsDefault()) {
+    _impl_.message_.Set("", GetArenaForAllocation());
+  }
+#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
+  // @@protoc_insertion_point(field_set_allocated:events.Ack.message)
+}
+
+#ifdef __GNUC__
+  #pragma GCC diagnostic pop
+#endif  // __GNUC__
+// -------------------------------------------------------------------
+
+
+// @@protoc_insertion_point(namespace_scope)
+
+}  // namespace events
+
+// @@protoc_insertion_point(global_scope)
+
+#include <google/protobuf/port_undef.inc>
+#endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_event_2eproto
diff --git a/grpc/event.proto b/grpc/event.proto
new file mode 100644
index 0000000..fc28ab6
--- /dev/null
+++ b/grpc/event.proto
@@ -0,0 +1,23 @@
+syntax = "proto3";
+
+package events;
+
+message Event {
+  string flight_id = 1;
+  string seat = 2;
+  string user_id = 3;
+  string customer_name = 4;
+  string status = 5;
+  string payment_method = 6;
+  string reservation_time = 7;
+  string price = 8;
+  int64 timestamp = 9;
+}
+
+message Ack {
+  string message = 1;
+}
+
+service EventService {
+  rpc SendEvent(Event) returns (Ack);
+}
\ No newline at end of file
diff --git a/grpc/event_pb2.py b/grpc/event_pb2.py
new file mode 100644
index 0000000..70ec971
--- /dev/null
+++ b/grpc/event_pb2.py
@@ -0,0 +1,40 @@
+# -*- coding: utf-8 -*-
+# Generated by the protocol buffer compiler.  DO NOT EDIT!
+# NO CHECKED-IN PROTOBUF GENCODE
+# source: event.proto
+# Protobuf Python Version: 5.29.0
+"""Generated protocol buffer code."""
+from google.protobuf import descriptor as _descriptor
+from google.protobuf import descriptor_pool as _descriptor_pool
+from google.protobuf import runtime_version as _runtime_version
+from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
+_runtime_version.ValidateProtobufRuntimeVersion(
+    _runtime_version.Domain.PUBLIC,
+    5,
+    29,
+    0,
+    '',
+    'event.proto'
+)
+# @@protoc_insertion_point(imports)
+
+_sym_db = _symbol_database.Default()
+
+
+
+
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x0b\x65vent.proto\x12\x06\x65vents\"\xb4\x01\n\x05\x45vent\x12\x11\n\tflight_id\x18\x01 \x01(\t\x12\x0c\n\x04seat\x18\x02 \x01(\t\x12\x0f\n\x07user_id\x18\x03 \x01(\t\x12\x15\n\rcustomer_name\x18\x04 \x01(\t\x12\x0e\n\x06status\x18\x05 \x01(\t\x12\x16\n\x0epayment_method\x18\x06 \x01(\t\x12\x18\n\x10reservation_time\x18\x07 \x01(\t\x12\r\n\x05price\x18\x08 \x01(\t\x12\x11\n\ttimestamp\x18\t \x01(\x03\"\x16\n\x03\x41\x63k\x12\x0f\n\x07message\x18\x01 \x01(\t27\n\x0c\x45ventService\x12\'\n\tSendEvent\x12\r.events.Event\x1a\x0b.events.Ackb\x06proto3')
+
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'event_pb2', _globals)
+if not _descriptor._USE_C_DESCRIPTORS:
+  DESCRIPTOR._loaded_options = None
+  _globals['_EVENT']._serialized_start=24
+  _globals['_EVENT']._serialized_end=204
+  _globals['_ACK']._serialized_start=206
+  _globals['_ACK']._serialized_end=228
+  _globals['_EVENTSERVICE']._serialized_start=230
+  _globals['_EVENTSERVICE']._serialized_end=285
+# @@protoc_insertion_point(module_scope)
diff --git a/grpc/event_pb2_grpc.py b/grpc/event_pb2_grpc.py
new file mode 100644
index 0000000..ddb6a46
--- /dev/null
+++ b/grpc/event_pb2_grpc.py
@@ -0,0 +1,97 @@
+# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
+"""Client and server classes corresponding to protobuf-defined services."""
+import grpc
+import warnings
+
+import event_pb2 as event__pb2
+
+GRPC_GENERATED_VERSION = '1.71.0'
+GRPC_VERSION = grpc.__version__
+_version_not_supported = False
+
+try:
+    from grpc._utilities import first_version_is_lower
+    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
+except ImportError:
+    _version_not_supported = True
+
+if _version_not_supported:
+    raise RuntimeError(
+        f'The grpc package installed is at version {GRPC_VERSION},'
+        + f' but the generated code in event_pb2_grpc.py depends on'
+        + f' grpcio>={GRPC_GENERATED_VERSION}.'
+        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
+        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
+    )
+
+
+class EventServiceStub(object):
+    """Missing associated documentation comment in .proto file."""
+
+    def __init__(self, channel):
+        """Constructor.
+
+        Args:
+            channel: A grpc.Channel.
+        """
+        self.SendEvent = channel.unary_unary(
+                '/events.EventService/SendEvent',
+                request_serializer=event__pb2.Event.SerializeToString,
+                response_deserializer=event__pb2.Ack.FromString,
+                _registered_method=True)
+
+
+class EventServiceServicer(object):
+    """Missing associated documentation comment in .proto file."""
+
+    def SendEvent(self, request, context):
+        """Missing associated documentation comment in .proto file."""
+        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+        context.set_details('Method not implemented!')
+        raise NotImplementedError('Method not implemented!')
+
+
+def add_EventServiceServicer_to_server(servicer, server):
+    rpc_method_handlers = {
+            'SendEvent': grpc.unary_unary_rpc_method_handler(
+                    servicer.SendEvent,
+                    request_deserializer=event__pb2.Event.FromString,
+                    response_serializer=event__pb2.Ack.SerializeToString,
+            ),
+    }
+    generic_handler = grpc.method_handlers_generic_handler(
+            'events.EventService', rpc_method_handlers)
+    server.add_generic_rpc_handlers((generic_handler,))
+    server.add_registered_method_handlers('events.EventService', rpc_method_handlers)
+
+
+ # This class is part of an EXPERIMENTAL API.
+class EventService(object):
+    """Missing associated documentation comment in .proto file."""
+
+    @staticmethod
+    def SendEvent(request,
+            target,
+            options=(),
+            channel_credentials=None,
+            call_credentials=None,
+            insecure=False,
+            compression=None,
+            wait_for_ready=None,
+            timeout=None,
+            metadata=None):
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            '/events.EventService/SendEvent',
+            event__pb2.Event.SerializeToString,
+            event__pb2.Ack.FromString,
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+            _registered_method=True)
diff --git a/grpc/requirements.txt b/grpc/requirements.txt
new file mode 100644
index 0000000..7b77c8a
--- /dev/null
+++ b/grpc/requirements.txt
@@ -0,0 +1,5 @@
+grpcio
+grpcio-tools
+pandas
+faker
+protobuf
\ No newline at end of file
diff --git a/grpc/response_times.csv b/grpc/response_times.csv
new file mode 100644
index 0000000..8bce296
--- /dev/null
+++ b/grpc/response_times.csv
@@ -0,0 +1,24 @@
+num_clients,avg_response_time
+
+1,0.0014071800003875978
+1,0.9507353625995165
+2,1.2075996797997504
+3,1.3627938596669993
+4,1.7968767108000976
+5,1.889571241960075
+8,3.260256811550062
+6,2.4542918602661907
+7,2.9993866321995615
+8,3.849325695650168
+9,4.466358953000033
+10,4.924035598919727
+11,5.46843742452706
+12,6.103630730283475
+13,8.05908714736926
+14,7.751195264043053
+15,7.70950936033342
+16,10.890007900899946
+17,10.614619594588465
+18,9.589396074244561
+19,10.68110449085258
+20,13.687951567520066
diff --git a/src/Makefile b/src/Makefile
index 7da56e6..5709a2c 100644
--- a/src/Makefile
+++ b/src/Makefile
@@ -1,22 +1,55 @@
 SQLITE_DIR = ../libs/sqlite3
+GRPC_DIR = ../grpc
 TARGET_DIR = ./exes
-TARGET = $(TARGET_DIR)/main.exe
+TARGET = $(TARGET_DIR)/server.exe
 
-# Lista dos seus arquivos C++ (adicione/remova aqui)
-CPP_SOURCES = main.cpp
+CPP_SOURCES = server.cpp
+PROTO_SOURCES = $(GRPC_DIR)/event.pb.cc $(GRPC_DIR)/event.grpc.pb.cc
 
-# Regra principal
-all:
-	mkdir -p $(TARGET_DIR)
-	gcc -Wno-unused-but-set-variable -I$(SQLITE_DIR) -c $(SQLITE_DIR)/sqlite3.c
-	g++ -std=c++17 -I$(SQLITE_DIR) -I. $(CPP_SOURCES) sqlite3.o -o $(TARGET)
+TARGET_ETL = $(TARGET_DIR)/etl.exe
+CPP_SOURCES_ETL = main.cpp
+
+CXX = g++
+
+CXXFLAGS = -std=c++17 -I$(SQLITE_DIR) -I$(GRPC_DIR) -I.
+
+LDFLAGS = -lgrpc++ -lgrpc \
+          -lprotobuf \
+          -labsl_synchronization -labsl_raw_logging_internal -labsl_bad_optional_access \
+          -labsl_str_format_internal -labsl_time -labsl_base \
+          -laddress_sorting -lgpr -lupb -lcares -lre2 \
+          -lpthread -lssl -lcrypto
+
+all: $(TARGET_DIR) $(TARGET) $(TARGET_ETL)
+
+$(TARGET_DIR):
+	@mkdir -p $(TARGET_DIR)
+
+sqlite3.o: $(SQLITE_DIR)/sqlite3.c
+	gcc -Wno-unused-but-set-variable -I$(SQLITE_DIR) -c $< -o $@
+
+$(GRPC_DIR)/event.pb.o: $(GRPC_DIR)/event.pb.cc $(GRPC_DIR)/event.pb.h
+	$(CXX) $(CXXFLAGS) -c $< -o $@
+
+$(GRPC_DIR)/event.grpc.pb.o: $(GRPC_DIR)/event.grpc.pb.cc $(GRPC_DIR)/event.grpc.pb.h
+	$(CXX) $(CXXFLAGS) -c $< -o $@
+
+server.o: server.cpp
+	$(CXX) $(CXXFLAGS) -c $< -o $@
+
+main.o: main.cpp
+	$(CXX) $(CXXFLAGS) -c $< -o $@
+
+$(TARGET): sqlite3.o server.o $(GRPC_DIR)/event.pb.o $(GRPC_DIR)/event.grpc.pb.o
+	$(CXX) -o $@ $^ $(LDFLAGS)
+
+$(TARGET_ETL): main.o sqlite3.o
+	$(CXX) -o $@ $^ $(LDFLAGS)
 
-# Limpeza
 clean:
-	rm -f $(TARGET) sqlite3.o *.db ../databases/* 2>/dev/null || del $(TARGET) sqlite3.o *.db ..\databases\*.db 2>nul
+	rm -f $(TARGET) $(TARGET_ETL) *.o *.db ../databases/*.db 2>/dev/null || true
 
-# Execução
-run:
-	./$(TARGET) || .\$(TARGET)
+run: $(TARGET)
+	./$(TARGET)
 
-.PHONY: all clean run
+.PHONY: all clean run
\ No newline at end of file
diff --git a/src/database.h b/src/database.h
index 805abe2..7055805 100644
--- a/src/database.h
+++ b/src/database.h
@@ -9,6 +9,7 @@
 #include <cstring>
 #include "sqlite3.h"
 #include <mutex>
+#include "dataframe.hpp"
 
 class DataBase {
 public:
@@ -25,6 +26,16 @@ public:
             std::cerr << "Erro ao abrir o banco de dados: " << sqlite3_errmsg(db) << std::endl;
             throw std::runtime_error("Erro ao abrir o banco de dados");
         }
+        // Set busy timeout to 5 seconds (5000 milliseconds)
+        sqlite3_busy_timeout(db, 5000);
+
+        // ADDED: Set WAL journal mode for better concurrency
+        const char* wal_pragma = "PRAGMA journal_mode=WAL;";
+        int wal_rc = sqlite3_exec(db, wal_pragma, nullptr, nullptr, &errMsg);
+        if (wal_rc != SQLITE_OK) {
+            std::cerr << "Erro ao definir journal_mode para WAL: " << errMsg << std::endl;
+            sqlite3_free(errMsg);
+        }
     }
 
     ~DataBase() {
@@ -89,8 +100,8 @@ public:
     }
 
     void bulkInsert(const std::string& table_name, 
-        const DataFrame<std::string>& df, 
-        const std::vector<std::string>& columns) {
+                const DataFrame<std::string>& df,
+                const std::vector<std::string>& columns) {
 
         sqlite3_stmt *stmt;
 
@@ -143,7 +154,7 @@ public:
     // imprimir a tabela
     void printTable(const std::string& tableName) {
         std::lock_guard<std::mutex> lock(dbMutex);
-        auto callback = [](void* data, int argc, char** argv, char** colNames) -> int {
+        auto callback = [](void* /*data*/, int argc, char** argv, char** colNames) -> int {
             for(int i = 0; i < argc; i++) {
                 std::cout << colNames[i] << ": " << (argv[i] ? argv[i] : "NULL") << "\t";
             }
@@ -185,4 +196,4 @@ public:
     }
 };
 
-#endif // DATABASE_H
+#endif // DATABASE_H
\ No newline at end of file
diff --git a/src/dataframe.hpp b/src/dataframe.hpp
index d4403f4..526db44 100644
--- a/src/dataframe.hpp
+++ b/src/dataframe.hpp
@@ -468,7 +468,7 @@ DataFrame<T> extractFirstNLines(int n) {
 private:
     // achar o index da coluna por nome
     int column_id(const std::string& columnName) const {
-        for (int i = 0; i < columns.size(); i++) {
+        for (size_t i = 0; i < columns.size(); i++) { 
             if (columns[i] == columnName) {
                 return i;
             }
diff --git a/src/etl.cpp b/src/etl.cpp
new file mode 100644
index 0000000..6e6f232
--- /dev/null
+++ b/src/etl.cpp
@@ -0,0 +1,278 @@
+#include <iostream>
+#include <vector>
+#include <chrono>
+#include <iomanip>
+#include <random>
+#include <mutex>
+#include "dataframe.hpp"
+#include "extractor.hpp"
+#include "trigger.hpp"
+#include "handler.hpp"
+#include "database.h"
+#include "loader.hpp"
+#include "threadPool.hpp"
+#include "queue.hpp"
+
+using Clock = std::chrono::high_resolution_clock;
+
+// Global mutex for thread-safe printing
+std::mutex table_mutex;
+
+void printTableHeader()
+{
+    std::lock_guard<std::mutex> lock(table_mutex);
+    std::cout << "\n----------------------------------------------------------------------------------------------------------------------------------------------------------" << std::endl;
+    std::cout << "| Trigger   | Lines | Seq. Process | Seq. Load | Par. (4) Process | Par. (4) Load | Par. (8) Process | Par. (8) Load | Par. (12) Process | Par. (12) Load |" << std::endl;
+    std::cout << "------------------------------------------------------------------------------------------------------------------------------------------------------------" << std::endl;
+}
+
+void printTableRow(const std::string &triggerType, size_t linesProcessed,
+                   const long &seqProc, const long &seqLoad,
+                   const long &par4Proc, const long &par4Load,
+                   const long &par8Proc, const long &par8Load,
+                   const long &par12Proc, const long &par12Load)
+{
+    std::lock_guard<std::mutex> lock(table_mutex);
+    std::cout << "| " << std::setw(9) << std::left << triggerType
+              << " | " << std::setw(5) << std::right << linesProcessed
+              << " | " << std::setw(12) << std::right << seqProc
+              << " | " << std::setw(9) << std::right << seqLoad
+              << " | " << std::setw(16) << std::right << par4Proc
+              << " | " << std::setw(13) << std::right << par4Load
+              << " | " << std::setw(16) << std::right << par8Proc
+              << " | " << std::setw(13) << std::right << par8Load
+              << " | " << std::setw(16) << std::right << par12Proc
+              << " | " << std::setw(13) << std::right << par12Load
+              << " |" << std::endl;
+    std::cout << "------------------------------------------------------------------------------------------------------------------------------------------------------------" << std::endl;
+}
+
+struct TestResults
+{
+    struct RunStats
+    {
+        // Processing times
+        long sequentialProcessingTime = 0;
+        long sequentialLoadTime = 0;
+        long parallel4ProcessingTime = 0;
+        long parallel4LoadTime = 0;
+        long parallel8ProcessingTime = 0;
+        long parallel8LoadTime = 0;
+        long parallel12ProcessingTime = 0;
+        long parallel12LoadTime = 0;
+
+        // Metadata
+        size_t linesProcessed = 0;
+        std::string triggerType;
+        std::chrono::time_point<Clock> startTime;
+        std::chrono::time_point<Clock> endTime;
+    };
+
+    std::vector<RunStats> allRuns;
+};
+
+unsigned int getOptimalThreadCount() {
+    unsigned int available_threads = std::thread::hardware_concurrency();
+    
+    // Se não conseguir detectar, usa um valor padrão seguro (4 threads)
+    if(available_threads == 0) {
+        std::cerr << "Não foi possível detectar o número de núcleos. Usando 4 threads como padrão." << std::endl;
+        return 4;
+    }
+    
+    std::cout << "Número de threads disponíveis: " << available_threads << std::endl;
+    return available_threads;
+}
+
+void processParallelChunk(int numThreads, DataBase &db, const std::string &nomeArquivo,
+    DataFrame<std::string> &df,
+    TestResults::RunStats &stats,
+    bool bfirstTime)
+{
+    auto start = Clock::now();
+    std::string tableSuffix = "_" + nomeArquivo + "_" + std::to_string(numThreads);
+
+    std::shared_ptr<const DataFrame<std::string>> users_df;
+    std::shared_ptr<const DataFrame<std::string>> flight_seats_df;
+    std::shared_ptr<const DataFrame<std::string>> flights_df;
+    std::unordered_map<std::string, std::string> userIdToCountry;
+    std::unordered_map<std::string, std::string> seatKeyToClass;
+    std::vector<DataFrame<std::string>> dfMeanPrices;
+
+    Extractor extractor;
+    users_df = std::make_shared<const DataFrame<std::string>>(
+        extractor.extractFromCsv("../generator/users.csv")
+    );
+    flight_seats_df = std::make_shared<const DataFrame<std::string>>(
+        extractor.extractFromCsv("../generator/flights_seats.csv")
+    );
+    flights_df = std::make_shared<const DataFrame<std::string>>(
+        extractor.extractFromCsv("../generator/flights.csv")
+    );
+
+    if (bfirstTime)
+    {
+        db.createTable("faturamento" + tableSuffix, "(reservation_time TEXT PRIMARY KEY, price REAL)");
+        db.createTable("faturamentoMetodo" + tableSuffix, "(payment_method TEXT PRIMARY KEY, price REAL)");
+        db.createTable("faturamentoPaisUsuario" + tableSuffix, "(user_country TEXT PRIMARY KEY, price REAL)");
+        db.createTable("faturamentoTipoAssento" + tableSuffix, "(seat_type TEXT PRIMARY KEY, price REAL)");
+        db.createTable("flight_stats" + tableSuffix, "(flight_number TEXT PRIMARY KEY, reservation_count INTEGER)");
+        db.createTable("destination_stats" + tableSuffix, "(destination TEXT PRIMARY KEY, reservation_count INTEGER)");
+        db.createTable("precoMedioPorDestino" + tableSuffix, "(destination TEXT PRIMARY KEY, mean_avg_price REAL)");
+        db.createTable("precoMedioPorAirline" + tableSuffix, "(airline TEXT PRIMARY KEY, mean_avg_price REAL)");
+
+        MeanPricePerDestination_AirlineHandler MeanPriceHandler;
+        dfMeanPrices = MeanPriceHandler.processMultiShared({flight_seats_df, flights_df});
+        dfMeanPrices[0].renameColumn("to", "destination");
+    }
+
+    for (int i = 0; i < users_df->numRows(); ++i)
+            userIdToCountry[users_df->getValue("user_id", i)] = users_df->getValue("country", i);
+    
+    for (int i = 0; i < flight_seats_df->numRows(); ++i)
+        seatKeyToClass[flight_seats_df->getValue("flight_id", i) + "_" + flight_seats_df->getValue("seat", i)] =
+            flight_seats_df->getValue("seat_class", i);
+
+    // Create shared handlers
+    auto sharedFlightEnricher = std::make_shared<FlightInfoEnricherHandler>(*flights_df);
+    auto sharedDestinationCounter = std::make_shared<DestinationCounterHandler>();
+
+    ThreadPool pool(numThreads);
+    Queue<int, DataFrame<std::string>> partitionQueue(numThreads);
+    Queue<int, DataFrame<std::string>> processedQueue(numThreads);
+    Queue<int, DataFrame<std::string>> userCountryQueue(numThreads);
+    Queue<int, DataFrame<std::string>> seatTypeQueue(numThreads);
+    Queue<int, DataFrame<std::string>> flightStatsQueue(numThreads);
+    Queue<int, DataFrame<std::string>> destinationStatsQueue(numThreads);
+
+    // Partition the data
+    size_t chunk_size = df.numRows() / numThreads;
+    for (int i = 0; i < numThreads; ++i)
+    {
+        size_t start_idx = i * chunk_size;
+        size_t end_idx = (i == numThreads - 1) ? df.numRows() : start_idx + chunk_size;
+        partitionQueue.enQueue({i, df.extractLines(start_idx, end_idx)});
+    }
+
+    // Processing phase
+    auto startProcessing = Clock::now();
+    std::vector<std::future<void>> processingFutures;
+
+    ValidationHandler validationHandler;
+    StatusFilterHandler statusFilterHandler("confirmed");
+    DateHandler dateHandler;
+    
+    // Instâncias únicas thread-safe
+    auto sharedUserHandler = std::make_shared<UsersCountryRevenue>(userIdToCountry);
+    auto sharedSeatHandler = std::make_shared<SeatTypeRevenue>(seatKeyToClass);
+
+    for (int i = 0; i < numThreads; ++i)
+    {
+        processingFutures.push_back(pool.addTask([&, i, sharedUserHandler, sharedSeatHandler, sharedFlightEnricher, sharedDestinationCounter]()
+        {
+            auto [idx, chunk] = partitionQueue.deQueue();
+            auto processed = validationHandler.process(chunk);
+            processed = statusFilterHandler.process(processed);
+
+            // Process flight enrichment
+            auto flightResults = sharedFlightEnricher->processMulti({processed});
+            DataFrame<std::string> enrichedDf = flightResults[0];
+            DataFrame<std::string> flightStats = flightResults[1];
+            
+            // Process destination stats
+            DataFrame<std::string> destinationStats = sharedDestinationCounter->process(enrichedDf);
+            
+            // Process other handlers
+            DataFrame<std::string> countryRevenue = sharedUserHandler->process(enrichedDf);
+            DataFrame<std::string> seatRevenue = sharedSeatHandler->process(enrichedDf);
+
+            userCountryQueue.enQueue({idx, countryRevenue});
+            seatTypeQueue.enQueue({idx, seatRevenue});
+            flightStatsQueue.enQueue({idx, flightStats});
+            destinationStatsQueue.enQueue({idx, destinationStats});
+
+            processed = dateHandler.process(enrichedDf);
+            processedQueue.enQueue({idx, processed});
+        }));
+    }
+
+    for (auto &fut : processingFutures)
+        fut.get();
+    auto endProcessing = Clock::now();
+
+    // Aggregate all processed data
+    DataFrame<std::string> allProcessed;
+    for (int i = 0; i < numThreads; ++i)
+    {
+        auto [idx, processed] = processedQueue.deQueue();
+        allProcessed = (i == 0) ? processed : allProcessed.concat(processed);
+    }
+
+    // Aggregate user country data
+    DataFrame<std::string> allUserCountry;
+    for (int i = 0; i < numThreads; ++i)
+    {
+        auto [idx, countryDf] = userCountryQueue.deQueue();
+        allUserCountry = (i == 0) ? countryDf : allUserCountry.concat(countryDf);
+    }
+
+    // Aggregate seat type data
+    DataFrame<std::string> allSeatType;
+    for (int i = 0; i < numThreads; ++i)
+    {
+        auto [idx, seatDf] = seatTypeQueue.deQueue();
+        allSeatType = (i == 0) ? seatDf : allSeatType.concat(seatDf);
+    }
+
+    // Aggregate flight stats
+    DataFrame<std::string> allFlightStats;
+    for (int i = 0; i < numThreads; ++i)
+    {
+        auto [idx, flightDf] = flightStatsQueue.deQueue();
+        allFlightStats = (i == 0) ? flightDf : allFlightStats.concat(flightDf);
+    }
+
+    // Aggregate destination stats
+    DataFrame<std::string> allDestinationStats;
+    for (int i = 0; i < numThreads; ++i)
+    {
+        auto [idx, destDf] = destinationStatsQueue.deQueue();
+        allDestinationStats = (i == 0) ? destDf : allDestinationStats.concat(destDf);
+    }
+
+    // Final aggregation phase
+    auto startAggregation = Clock::now();
+    RevenueHandler revenueHandler;
+    CardRevenueHandler cardHandler;
+
+    DataFrame<std::string> revenue = revenueHandler.process(allProcessed);
+    DataFrame<std::string> cards = cardHandler.process(allProcessed);
+
+    auto aggregatedRevenue = revenue.groupby("reservation_time", "price");
+    auto aggregatedCards = cards.groupby("payment_method", "price");
+    auto aggregatedFlightStats = allFlightStats.groupby("flight_number", "reservation_count");
+    auto aggregatedDestinationStats = allDestinationStats.groupby("destination", "reservation_count");
+    auto aggregatedUserCountry = allUserCountry.groupby("user_country", "price");
+    auto aggregatedSeatType = allSeatType.groupby("seat_type", "price");
+    auto endAggregation = Clock::now();
+
+    // Load all data into DB
+    Loader loader(db);
+    auto startLoad = Clock::now();
+    loader.loadData("faturamento" + tableSuffix, aggregatedRevenue, {"reservation_time", "price"}, false);
+    loader.loadData("faturamentoMetodo" + tableSuffix, aggregatedCards, {"payment_method", "price"}, false);
+    loader.loadData("faturamentoPaisUsuario" + tableSuffix, aggregatedUserCountry, {"user_country", "price"}, false);
+    loader.loadData("faturamentoTipoAssento" + tableSuffix, aggregatedSeatType, {"seat_type", "price"}, false);
+    loader.loadData("flight_stats" + tableSuffix, aggregatedFlightStats, {"flight_number", "reservation_count"}, false);
+    loader.loadData("destination_stats" + tableSuffix, aggregatedDestinationStats, {"destination", "reservation_count"}, false);
+    if (bfirstTime)
+    {
+        loader.loadData("precoMedioPorDestino" + tableSuffix, dfMeanPrices[0], {"destination", "mean_avg_price"}, false);
+        loader.loadData("precoMedioPorAirline" + tableSuffix, dfMeanPrices[1], {"airline", "mean_avg_price"}, false);
+    }
+
+    auto endLoad = Clock::now();
+
+    long aggregationTime = std::chrono::duration_cast<std::chrono::milliseconds>(endAggregation - startAggregation).count();
+    long processingTime = std::chrono::duration_cast<std::chrono::milliseconds>(endProcessing - startProcessing).count();
+}
\ No newline at end of file
diff --git a/src/exes/etl.exe b/src/exes/etl.exe
new file mode 100755
index 0000000..81c852c
Binary files /dev/null and b/src/exes/etl.exe differ
diff --git a/src/extractor.hpp b/src/extractor.hpp
index 10fff38..0532bc1 100644
--- a/src/extractor.hpp
+++ b/src/extractor.hpp
@@ -5,10 +5,15 @@
 #include <iostream>
 #include "dataframe.hpp"
 #include "queue.hpp"
+#include "event.pb.h"
 #include <sqlite3.h>
 #include <mutex>
 #include <random>
 
+namespace events {
+    class Event;  // Forward declaration
+}
+
 class Extractor {
 private:
     std::unordered_map<std::string, size_t> file_positions;
@@ -288,34 +293,49 @@ public:
                 throw std::runtime_error("Failed to execute query: " + std::string(sqlite3_errmsg(db)));
             }
 
-            std::vector<std::string> columns;
+            std::vector<std::string> columns_from_db; // To store column names retrieved from DB
             std::vector<std::vector<std::string>> data;
 
             // Get column names
             int columnCount = sqlite3_column_count(stmt);
             for (int i = 0; i < columnCount; ++i) {
-                columns.push_back(sqlite3_column_name(stmt, i));
+                columns_from_db.push_back(sqlite3_column_name(stmt, i));
             }
 
             // Get rows of data
             while (sqlite3_step(stmt) == SQLITE_ROW) {
                 std::vector<std::string> row;
                 for (int i = 0; i < columnCount; ++i) {
-                    row.push_back(reinterpret_cast<const char*>(sqlite3_column_text(stmt, i)));
+                    // Get column name for type-specific extraction
+                    std::string colName = sqlite3_column_name(stmt, i);
+                    
+                    // Check if the column value is NULL
+                    if (sqlite3_column_type(stmt, i) == SQLITE_NULL) {
+                        row.push_back(""); // Replace NULL with empty string
+                    } else {
+                        // Special handling for timestamp, which is INTEGER
+                        if (colName == "timestamp") {
+                            long long timestamp_val = sqlite3_column_int64(stmt, i);
+                            row.push_back(std::to_string(timestamp_val));
+                        } else {
+                            const char* val = reinterpret_cast<const char*>(sqlite3_column_text(stmt, i));
+                            row.push_back(val ? val : ""); // Handle non-NULL string values
+                        }
+                    }
                 }
                 data.push_back(row);
             }
 
-            char* errMsg;
-            query = ("DELETE FROM " + tableName + ";");
-            rc = sqlite3_exec(db, query.c_str(), nullptr, nullptr, &errMsg);
+            // char* errMsg;
+            // query = ("DELETE FROM " + tableName + ";"); // This deletes all data from the table
+            // rc = sqlite3_exec(db, query.c_str(), nullptr, nullptr, &errMsg); // COMMENTED OUT
 
             sqlite3_finalize(stmt);
             sqlite3_close(db);
 
-            // Prepare tne DataFrame
+            // Prepare the DataFrame
             std::vector<Series<std::string>> series;
-            for (size_t i = 0; i < columns.size(); ++i) {
+            for (size_t i = 0; i < columns_from_db.size(); ++i) {
                 std::vector<std::string> columnData;
                 for (const auto& row : data) {
                     columnData.push_back(row[i]);
@@ -323,7 +343,7 @@ public:
                 series.push_back(Series<std::string>(columnData));
             }
 
-            DataFrame<std::string> resultDf = DataFrame<std::string>(columns, series);
+            DataFrame<std::string> resultDf = DataFrame<std::string>(columns_from_db, series);
 
             return resultDf;
         } catch (const std::exception& e) {
@@ -392,4 +412,27 @@ public:
             throw;
         }
     }
+
+    DataFrame<std::string> extractFromGrpcEvent(const events::Event* event) {
+        std::vector<std::string> columns = {
+            "flight_id", "seat", "user_id", "customer_name",
+            "status", "payment_method", "reservation_time", 
+            "price", "timestamp"
+        };
+
+        std::vector<Series<std::string>> series;
+        series.reserve(columns.size());  
+        
+        series.emplace_back(std::vector<std::string>{event->flight_id()});
+        series.emplace_back(std::vector<std::string>{event->seat()});
+        series.emplace_back(std::vector<std::string>{event->user_id()});
+        series.emplace_back(std::vector<std::string>{event->customer_name()});
+        series.emplace_back(std::vector<std::string>{event->status()});
+        series.emplace_back(std::vector<std::string>{event->payment_method()});
+        series.emplace_back(std::vector<std::string>{event->reservation_time()});
+        series.emplace_back(std::vector<std::string>{event->price()});
+        series.emplace_back(std::vector<std::string>{std::to_string(event->timestamp())});
+
+        return DataFrame<std::string>(columns, series);
+    }
 };
\ No newline at end of file
diff --git a/src/main.cpp b/src/main.cpp
index 2bff4d3..322401b 100644
--- a/src/main.cpp
+++ b/src/main.cpp
@@ -10,7 +10,7 @@
 #include "handler.hpp"
 #include "database.h"
 #include "loader.hpp"
-#include "ThreadPool.hpp"
+#include "threadPool.hpp"
 #include "queue.hpp"
 
 using Clock = std::chrono::high_resolution_clock;
@@ -71,6 +71,19 @@ struct TestResults
     std::vector<RunStats> allRuns;
 };
 
+unsigned int getOptimalThreadCount() {
+    unsigned int available_threads = std::thread::hardware_concurrency();
+    
+    // Se não conseguir detectar, usa um valor padrão seguro (4 threads)
+    if(available_threads == 0) {
+        std::cerr << "Não foi possível detectar o número de núcleos. Usando 4 threads como padrão." << std::endl;
+        return 4;
+    }
+    
+    std::cout << "Número de threads disponíveis: " << available_threads << std::endl;
+    return available_threads;
+}
+
 void processParallelChunk(int numThreads, DataBase &db, const std::string &nomeArquivo,
     DataFrame<std::string> &df,
     TestResults::RunStats &stats,
@@ -195,6 +208,8 @@ void processParallelChunk(int numThreads, DataBase &db, const std::string &nomeA
         allProcessed = (i == 0) ? processed : allProcessed.concat(processed);
     }
 
+    allProcessed.print();
+
     // Aggregate user country data
     DataFrame<std::string> allUserCountry;
     for (int i = 0; i < numThreads; ++i)
@@ -292,7 +307,7 @@ void Test()
 
     DataBase dbMock("../databases/MockSQL.db");
     Loader loaderMock(dbMock);
-    std::string createQuery = "(flight_id TEXT, seat TEXT, user_id BIGINT, customer_name TEXT, status TEXT, payment_method TEXT, reservation_time DATE, price FLOAT)";
+    std::string createQuery = "(flight_id TEXT, seat TEXT, user_id BIGINT, customer_name TEXT, status TEXT, payment_method TEXT, reservation_time DATE, price FLOAT, timestamp INTEGER)";
     dbMock.createTable("MockData", createQuery);
 
     bool bFirstTime = true;
@@ -304,14 +319,46 @@ void Test()
         if (df.numRows() == 0)
         {
             extractor.resetFilePosition(file_path);
+            // DEBUG: DataFrame is empty. Skipping processing.
             return;
         }
 
+        long total_latency = 0;
+        long valid_timestamp_count = 0;
+        auto now = std::chrono::system_clock::now();
+        auto now_ms = std::chrono::time_point_cast<std::chrono::milliseconds>(now);
+        long current_time = now_ms.time_since_epoch().count();
+
+        for (int i = 0; i < df.numRows(); ++i) {
+            std::string timestamp_str = df.getValue("timestamp", i);
+            // DEBUG: Timestamp string: [" << timestamp_str << "]
+            try {
+                long event_time = std::stol(timestamp_str);
+                if (event_time != 0) {
+                    total_latency += (current_time - event_time);
+                    valid_timestamp_count++;
+                } else {
+                    // DEBUG: Skipping timestamp '0' for latency calculation.
+                }
+            } catch (const std::invalid_argument& e) {
+                // ERROR: Invalid timestamp string for std::stol: [" << timestamp_str << "] - " << e.what()
+            } catch (const std::out_of_range& e) {
+                // ERROR: Timestamp string out of range for long: [" << timestamp_str << "] - " << e.what()
+            }
+        }
+
+        if (valid_timestamp_count > 0) {
+            long avg_latency = total_latency / valid_timestamp_count;
+            std::cout << "Average latency for " << triggerType << ": " << avg_latency << "ms\n";
+        } else {
+            std::cout << "No valid timestamps found for latency calculation in " << triggerType << " trigger." << std::endl;
+        }
+
+
         TestResults::RunStats stats;
         stats.triggerType = triggerType;
         stats.linesProcessed = df.numRows();
 
-        // Run all pipeline variants
         processParallelChunk(1, db, "orders", df, stats, bFirstTime);
         processParallelChunk(4, db, "orders", df, stats, bFirstTime);
         processParallelChunk(8, db, "orders", df, stats, bFirstTime);
@@ -321,7 +368,6 @@ void Test()
 
         results.allRuns.push_back(stats);
 
-        // Print to table with trigger type and line count
         printTableRow(stats.triggerType,
                       stats.linesProcessed,
                       stats.sequentialProcessingTime,
@@ -334,33 +380,24 @@ void Test()
                       stats.parallel12LoadTime);
     };
 
-    // We need this to pass into the jsonExtractor. It helps it being generic.
     std::vector<std::string> columns = {
-        "flight_id", "seat", "user_id", "customer_name", 
-        "status", "payment_method", "reservation_time", "price"
+        "flight_id", "seat", "user_id", "customer_name",
+        "status", "payment_method", "reservation_time", "price", "timestamp"
     };
-    
-    // SQLiteMockTrigger - insere dados aleatórios no SQLite
+
     auto SQLiteMockTrigger = std::make_shared<TimerTrigger>(1000);
     SQLiteMockTrigger->setCallback([&](){
-        // Extrai um chunk aleatório de dados
         DataFrame<std::string> df = extractor.extractRandomChunk(file_path, columns, 5000, 15000);
-        // Insere dados no bancos
-        loaderMock.loadData("MockData", df, {"flight_id", "seat", "user_id", "customer_name", "status", "payment_method", "reservation_time", "price"}, true);
+        loaderMock.loadData("MockData", df, {"flight_id", "seat", "user_id", "customer_name", "status", "payment_method", "reservation_time", "price", "timestamp"}, true);
     });
 
-    // TimerTrigger - processa dados do SQLite a cada 10 segundos
     auto timer_trigger = std::make_shared<TimerTrigger>(10000);
     timer_trigger->setCallback([&](){
-        // Consulta SQL para pegar os dados
         std::string tableName = "MockData";
         std::string dbFilePath = "../databases/MockSQL.db";
 
-        // Extrai dados do banco SQLite
         DataFrame<std::string> df = extractor.extractFromSqlite(dbFilePath, tableName);
-        // df.print();
 
-        // Verifica se há dados para processar
         if (df.numRows() > 0) {
             processFullPipeline("Timer", df);
         } else {
@@ -368,41 +405,20 @@ void Test()
         }
     });
 
-    // RequestTrigger - processes fixed 15000-line chunks
-    auto request_trigger = std::make_shared<RequestTrigger>();
-    request_trigger->setCallback([&]()
-    {
-        DataFrame<std::string> df = extractor.extractChunk(file_path, columns, 15000);
-        processFullPipeline("Request", df); 
-    });
-
-    // Start triggers
     SQLiteMockTrigger->start();
     timer_trigger->start();
-    request_trigger->start();
 
-    // Simulate random requests
     std::random_device rd;
     std::mt19937 gen(rd());
     std::uniform_int_distribution<> dist(2, 5);
 
-    for (int i = 0; i < 3; ++i)
-    {
-        std::this_thread::sleep_for(std::chrono::seconds(dist(gen)));
-        request_trigger->trigger();
-    }
-
-    // Run for 30 seconds
-    std::this_thread::sleep_for(std::chrono::seconds(30));
+    std::this_thread::sleep_for(std::chrono::seconds(60));
     SQLiteMockTrigger->stop();
     timer_trigger->stop();
-    request_trigger->stop();
 
-    // Final summary
     std::cout << "\n=== FINAL SUMMARY ===\n";
     std::cout << "Total executions: " << results.allRuns.size() << "\n";
 
-    // Calculate totals instead of averages
     long totalSeqProc = 0, totalSeqLoad = 0;
     long totalPar4Proc = 0, totalPar4Load = 0;
     long totalPar8Proc = 0, totalPar8Load = 0;
@@ -432,7 +448,8 @@ void Test()
 
 int main()
 {
-    Test();
-    
+    // Test();
+    std::cout << getOptimalThreadCount();
+
     return 0;
 }
\ No newline at end of file
diff --git a/src/main2.cpp b/src/main2.cpp
deleted file mode 100644
index 4ffb294..0000000
--- a/src/main2.cpp
+++ /dev/null
@@ -1,469 +0,0 @@
-#include <iostream>
-#include <vector>
-#include <chrono>
-#include <iomanip>
-#include <random>
-#include <mutex>
-#include "dataframe.hpp"
-#include "extractor.hpp"
-#include "trigger.hpp"
-#include "handler.hpp"
-#include "database.h"
-#include "loader.hpp"
-#include "ThreadPool.hpp"
-#include "queue.hpp"
-
-using Clock = std::chrono::high_resolution_clock;
-
-// Global mutex for thread-safe printing
-std::mutex table_mutex;
-
-void printTableHeader()
-{
-    std::lock_guard<std::mutex> lock(table_mutex);
-    std::cout << "\n----------------------------------------------------------------------------------------------------------------------------------------------------------" << std::endl;
-    std::cout << "| Trigger   | Lines | Seq. Process | Seq. Load | Par. (4) Process | Par. (4) Load | Par. (8) Process | Par. (8) Load | Par. (12) Process | Par. (12) Load |" << std::endl;
-    std::cout << "------------------------------------------------------------------------------------------------------------------------------------------------------------" << std::endl;
-}
-
-void printTableRow(const std::string &triggerType, size_t linesProcessed,
-                   const long &seqProc, const long &seqLoad,
-                   const long &par4Proc, const long &par4Load,
-                   const long &par8Proc, const long &par8Load,
-                   const long &par12Proc, const long &par12Load)
-{
-    std::lock_guard<std::mutex> lock(table_mutex);
-    std::cout << "| " << std::setw(9) << std::left << triggerType
-              << " | " << std::setw(5) << std::right << linesProcessed
-              << " | " << std::setw(12) << std::right << seqProc
-              << " | " << std::setw(9) << std::right << seqLoad
-              << " | " << std::setw(16) << std::right << par4Proc
-              << " | " << std::setw(13) << std::right << par4Load
-              << " | " << std::setw(16) << std::right << par8Proc
-              << " | " << std::setw(13) << std::right << par8Load
-              << " | " << std::setw(16) << std::right << par12Proc
-              << " | " << std::setw(13) << std::right << par12Load
-              << " |" << std::endl;
-    std::cout << "------------------------------------------------------------------------------------------------------------------------------------------------------------" << std::endl;
-}
-
-struct TestResults
-{
-    struct RunStats
-    {
-        // Processing times
-        long sequentialProcessingTime = 0;
-        long sequentialLoadTime = 0;
-        long parallel4ProcessingTime = 0;
-        long parallel4LoadTime = 0;
-        long parallel8ProcessingTime = 0;
-        long parallel8LoadTime = 0;
-        long parallel12ProcessingTime = 0;
-        long parallel12LoadTime = 0;
-
-        // Metadata
-        size_t linesProcessed = 0;
-        std::string triggerType;
-        std::chrono::time_point<Clock> startTime;
-        std::chrono::time_point<Clock> endTime;
-    };
-
-    std::vector<RunStats> allRuns;
-};
-
-void processSequentialChunk(DataBase &db, const std::string &nomeArquivo,
-    DataFrame<std::string> &df,
-    TestResults::RunStats &stats)
-{
-    stats.startTime = Clock::now();
-
-    // Load supporting data
-    Extractor extractor;
-    auto users_df = std::make_shared<const DataFrame<std::string>>(
-        extractor.extractFromCsv("../generator/users.csv")
-    );
-    auto flight_seats_df = std::make_shared<const DataFrame<std::string>>(
-        extractor.extractFromCsv("../generator/flights_seats.csv")
-    );
-    auto flights_df = std::make_shared<const DataFrame<std::string>>(
-        extractor.extractFromCsv("../generator/flights.csv")
-    );
-
-    // Criar os mapas uma vez
-    std::unordered_map<std::string, std::string> userIdToCountry;
-    for (int i = 0; i < users_df->numRows(); ++i) {
-        userIdToCountry[users_df->getValue("user_id", i)] = users_df->getValue("country", i);
-    }
-
-    std::unordered_map<std::string, std::string> seatKeyToClass;
-    for (int i = 0; i < flight_seats_df->numRows(); ++i) {
-        std::string key = flight_seats_df->getValue("flight_id", i) + "_" + flight_seats_df->getValue("seat", i);
-        seatKeyToClass[key] = flight_seats_df->getValue("seat_class", i);
-    }
-
-    // Create tables
-    db.createTable("faturamento_" + nomeArquivo, "(reservation_time TEXT PRIMARY KEY, price REAL)");
-    db.createTable("faturamentoMetodo_" + nomeArquivo, "(payment_method TEXT PRIMARY KEY, price REAL)");
-    db.createTable("faturamentoPaisUsuario_" + nomeArquivo, "(user_country TEXT PRIMARY KEY, price REAL)");
-    db.createTable("faturamentoTipoAssento_" + nomeArquivo, "(seat_type TEXT PRIMARY KEY, price REAL)");
-    db.createTable("flight_stats_" + nomeArquivo, "(flight_number TEXT PRIMARY KEY, reservation_count INTEGER)");
-    db.createTable("destination_stats_" + nomeArquivo, "(destination TEXT PRIMARY KEY, reservation_count INTEGER)");
-
-    // Processing
-    auto startProcessing = Clock::now();
-    ValidationHandler validationHandler;
-    StatusFilterHandler statusFilterHandler("confirmed");
-    UsersCountryRevenue userHandler(userIdToCountry);
-    SeatTypeRevenue seatHandler(seatKeyToClass);
-    DateHandler dateHandler;
-    RevenueHandler revenueHandler;
-    CardRevenueHandler cardHandler;
-    FlightInfoEnricherHandler flightEnricher(*flights_df);
-    DestinationCounterHandler destinationCounter;
-
-    DataFrame<std::string> processed = validationHandler.process(df);
-    processed = statusFilterHandler.process(processed);
-
-    // Run new handlers
-    auto flightResults = flightEnricher.processMulti({processed});
-    DataFrame<std::string> enrichedDf = flightResults[0];
-    DataFrame<std::string> flightStats = flightResults[1];
-    
-    DataFrame<std::string> destinationStats = destinationCounter.process(enrichedDf);
-    
-    DataFrame<std::string> porPais = userHandler.process(enrichedDf);
-    DataFrame<std::string> porClasse = seatHandler.process(enrichedDf);
-
-    processed = dateHandler.process(enrichedDf);
-    DataFrame<std::string> revenue = revenueHandler.process(processed);
-    DataFrame<std::string> cards = cardHandler.process(processed);
-    auto endProcessing = Clock::now();
-
-    // Loading
-    Loader loader(db);
-    auto startLoad = Clock::now();
-    loader.loadData("faturamento_" + nomeArquivo, revenue, {"reservation_time", "price"}, false);
-    loader.loadData("faturamentoMetodo_" + nomeArquivo, cards, {"payment_method", "price"}, false);
-    loader.loadData("faturamentoPaisUsuario_" + nomeArquivo, porPais, {"user_country", "price"}, false);
-    loader.loadData("faturamentoTipoAssento_" + nomeArquivo, porClasse, {"seat_type", "price"}, false);
-    loader.loadData("flight_stats_" + nomeArquivo, flightStats, {"flight_number", "reservation_count"}, false);
-    loader.loadData("destination_stats_" + nomeArquivo, destinationStats, {"destination", "reservation_count"}, false);
-    auto endLoad = Clock::now();
-
-    // Update stats
-    stats.sequentialProcessingTime = std::chrono::duration_cast<std::chrono::milliseconds>(endProcessing - startProcessing).count();
-    stats.sequentialLoadTime = std::chrono::duration_cast<std::chrono::milliseconds>(endLoad - startLoad).count();
-    stats.linesProcessed = df.numRows();
-    stats.endTime = Clock::now();
-}
-
-void processParallelChunk(int numThreads, DataBase &db, const std::string &nomeArquivo,
-    DataFrame<std::string> &df,
-    TestResults::RunStats &stats)
-{
-    auto start = Clock::now();
-
-    Extractor extractor;
-    auto users_df = std::make_shared<const DataFrame<std::string>>(
-        extractor.extractFromCsv("../generator/users.csv")
-    );
-    auto flight_seats_df = std::make_shared<const DataFrame<std::string>>(
-        extractor.extractFromCsv("../generator/flights_seats.csv")
-    );
-    auto flights_df = std::make_shared<const DataFrame<std::string>>(
-        extractor.extractFromCsv("../generator/flights.csv")
-    );
-
-    std::string tableSuffix = "_" + nomeArquivo + "_" + std::to_string(numThreads);
-    db.createTable("faturamento" + tableSuffix, "(reservation_time TEXT PRIMARY KEY, price REAL)");
-    db.createTable("faturamentoMetodo" + tableSuffix, "(payment_method TEXT PRIMARY KEY, price REAL)");
-    db.createTable("faturamentoPaisUsuario" + tableSuffix, "(user_country TEXT PRIMARY KEY, price REAL)");
-    db.createTable("faturamentoTipoAssento" + tableSuffix, "(seat_type TEXT PRIMARY KEY, price REAL)");
-    db.createTable("flight_stats" + tableSuffix, "(flight_number TEXT PRIMARY KEY, reservation_count INTEGER)");
-    db.createTable("destination_stats" + tableSuffix, "(destination TEXT PRIMARY KEY, reservation_count INTEGER)");
-
-    ThreadPool pool(numThreads);
-    Queue<int, DataFrame<std::string>> partitionQueue(numThreads);
-    Queue<int, DataFrame<std::string>> processedQueue(numThreads);
-    Queue<int, DataFrame<std::string>> userCountryQueue(numThreads);
-    Queue<int, DataFrame<std::string>> seatTypeQueue(numThreads);
-    Queue<int, DataFrame<std::string>> flightStatsQueue(numThreads);
-    Queue<int, DataFrame<std::string>> destinationStatsQueue(numThreads);
-
-    std::unordered_map<std::string, std::string> userIdToCountry;
-    for (int i = 0; i < users_df->numRows(); ++i)
-        userIdToCountry[users_df->getValue("user_id", i)] = users_df->getValue("country", i);
-
-    std::unordered_map<std::string, std::string> seatKeyToClass;
-    for (int i = 0; i < flight_seats_df->numRows(); ++i)
-        seatKeyToClass[flight_seats_df->getValue("flight_id", i) + "_" + flight_seats_df->getValue("seat", i)] =
-            flight_seats_df->getValue("seat_class", i);
-
-    // Create shared handlers
-    auto sharedFlightEnricher = std::make_shared<FlightInfoEnricherHandler>(*flights_df);
-    auto sharedDestinationCounter = std::make_shared<DestinationCounterHandler>();
-
-    // Partition the data
-    size_t chunk_size = df.numRows() / numThreads;
-    for (int i = 0; i < numThreads; ++i)
-    {
-        size_t start_idx = i * chunk_size;
-        size_t end_idx = (i == numThreads - 1) ? df.numRows() : start_idx + chunk_size;
-        partitionQueue.enQueue({i, df.extractLines(start_idx, end_idx)});
-    }
-
-    // Processing phase
-    auto startProcessing = Clock::now();
-    std::vector<std::future<void>> processingFutures;
-
-    ValidationHandler validationHandler;
-    StatusFilterHandler statusFilterHandler("confirmed");
-    DateHandler dateHandler;
-    
-    // Instâncias únicas thread-safe
-    auto sharedUserHandler = std::make_shared<UsersCountryRevenue>(userIdToCountry);
-    auto sharedSeatHandler = std::make_shared<SeatTypeRevenue>(seatKeyToClass);
-
-    for (int i = 0; i < numThreads; ++i)
-    {
-        processingFutures.push_back(pool.addTask([&, i, sharedUserHandler, sharedSeatHandler, sharedFlightEnricher, sharedDestinationCounter]()
-        {
-            auto [idx, chunk] = partitionQueue.deQueue();
-            auto processed = validationHandler.process(chunk);
-            processed = statusFilterHandler.process(processed);
-
-            // Process flight enrichment
-            auto flightResults = sharedFlightEnricher->processMulti({processed});
-            DataFrame<std::string> enrichedDf = flightResults[0];
-            DataFrame<std::string> flightStats = flightResults[1];
-            
-            // Process destination stats
-            DataFrame<std::string> destinationStats = sharedDestinationCounter->process(enrichedDf);
-            
-            // Process other handlers
-            DataFrame<std::string> countryRevenue = sharedUserHandler->process(enrichedDf);
-            DataFrame<std::string> seatRevenue = sharedSeatHandler->process(enrichedDf);
-
-            userCountryQueue.enQueue({idx, countryRevenue});
-            seatTypeQueue.enQueue({idx, seatRevenue});
-            flightStatsQueue.enQueue({idx, flightStats});
-            destinationStatsQueue.enQueue({idx, destinationStats});
-
-            processed = dateHandler.process(enrichedDf);
-            processedQueue.enQueue({idx, processed});
-        }));
-    }
-
-    for (auto &fut : processingFutures)
-        fut.get();
-    auto endProcessing = Clock::now();
-
-    // Aggregate all processed data
-    DataFrame<std::string> allProcessed;
-    for (int i = 0; i < numThreads; ++i)
-    {
-        auto [idx, processed] = processedQueue.deQueue();
-        allProcessed = (i == 0) ? processed : allProcessed.concat(processed);
-    }
-
-    // Aggregate user country data
-    DataFrame<std::string> allUserCountry;
-    for (int i = 0; i < numThreads; ++i)
-    {
-        auto [idx, countryDf] = userCountryQueue.deQueue();
-        allUserCountry = (i == 0) ? countryDf : allUserCountry.concat(countryDf);
-    }
-
-    // Aggregate seat type data
-    DataFrame<std::string> allSeatType;
-    for (int i = 0; i < numThreads; ++i)
-    {
-        auto [idx, seatDf] = seatTypeQueue.deQueue();
-        allSeatType = (i == 0) ? seatDf : allSeatType.concat(seatDf);
-    }
-
-    // Aggregate flight stats
-    DataFrame<std::string> allFlightStats;
-    for (int i = 0; i < numThreads; ++i)
-    {
-        auto [idx, flightDf] = flightStatsQueue.deQueue();
-        allFlightStats = (i == 0) ? flightDf : allFlightStats.concat(flightDf);
-    }
-
-    // Aggregate destination stats
-    DataFrame<std::string> allDestinationStats;
-    for (int i = 0; i < numThreads; ++i)
-    {
-        auto [idx, destDf] = destinationStatsQueue.deQueue();
-        allDestinationStats = (i == 0) ? destDf : allDestinationStats.concat(destDf);
-    }
-
-    // Final aggregation phase
-    auto startAggregation = Clock::now();
-    RevenueHandler revenueHandler;
-    CardRevenueHandler cardHandler;
-
-    DataFrame<std::string> revenue = revenueHandler.process(allProcessed);
-    DataFrame<std::string> cards = cardHandler.process(allProcessed);
-
-    auto aggregatedRevenue = revenue.groupby("reservation_time", "price");
-    auto aggregatedCards = cards.groupby("payment_method", "price");
-    auto aggregatedFlightStats = allFlightStats.groupby("flight_number", "reservation_count");
-    auto aggregatedDestinationStats = allDestinationStats.groupby("destination", "reservation_count");
-    auto aggregatedUserCountry = allUserCountry.groupby("user_country", "price");
-    auto aggregatedSeatType = allSeatType.groupby("seat_type", "price");
-    auto endAggregation = Clock::now();
-
-    // Load all data into DB
-    Loader loader(db);
-    auto startLoad = Clock::now();
-    loader.loadData("faturamento" + tableSuffix, aggregatedRevenue, {"reservation_time", "price"}, false);
-    loader.loadData("faturamentoMetodo" + tableSuffix, aggregatedCards, {"payment_method", "price"}, false);
-    loader.loadData("faturamentoPaisUsuario" + tableSuffix, aggregatedUserCountry, {"user_country", "price"}, false);
-    loader.loadData("faturamentoTipoAssento" + tableSuffix, aggregatedSeatType, {"seat_type", "price"}, false);
-    loader.loadData("flight_stats" + tableSuffix, aggregatedFlightStats, {"flight_number", "reservation_count"}, false);
-    loader.loadData("destination_stats" + tableSuffix, aggregatedDestinationStats, {"destination", "reservation_count"}, false);
-    auto endLoad = Clock::now();
-
-    long aggregationTime = std::chrono::duration_cast<std::chrono::milliseconds>(endAggregation - startAggregation).count();
-    long processingTime = std::chrono::duration_cast<std::chrono::milliseconds>(endProcessing - startProcessing).count();
-
-    switch (numThreads)
-    {
-        case 4:
-            stats.parallel4ProcessingTime = processingTime + aggregationTime;
-            stats.parallel4LoadTime = std::chrono::duration_cast<std::chrono::milliseconds>(endLoad - startLoad).count();
-            break;
-        case 8:
-            stats.parallel8ProcessingTime = processingTime + aggregationTime;
-            stats.parallel8LoadTime = std::chrono::duration_cast<std::chrono::milliseconds>(endLoad - startLoad).count();
-            break;
-        case 12:
-            stats.parallel12ProcessingTime = processingTime + aggregationTime;
-            stats.parallel12LoadTime = std::chrono::duration_cast<std::chrono::milliseconds>(endLoad - startLoad).count();
-            break;
-    }
-}
-
-void Test()
-{
-    Extractor extractor;
-    DataBase db("../databases/Database.db");
-    const std::string file_path = "../generator/orders.json";
-    TestResults results;
-
-    printTableHeader();
-
-    auto processFullPipeline = [&](const std::string &triggerType, DataFrame<std::string> df)
-    {
-        if (df.numRows() == 0)
-        {
-            extractor.resetFilePosition(file_path);
-            return;
-        }
-
-        TestResults::RunStats stats;
-        stats.triggerType = triggerType;
-        stats.linesProcessed = df.numRows();
-
-        // Run all pipeline variants
-        processSequentialChunk(db, "orders", df, stats);
-        processParallelChunk(4, db, "orders", df, stats);
-        processParallelChunk(8, db, "orders", df, stats);
-        processParallelChunk(12, db, "orders", df, stats);
-
-        results.allRuns.push_back(stats);
-
-        // Print to table with trigger type and line count
-        printTableRow(stats.triggerType,
-                      stats.linesProcessed,
-                      stats.sequentialProcessingTime,
-                      stats.sequentialLoadTime,
-                      stats.parallel4ProcessingTime,
-                      stats.parallel4LoadTime,
-                      stats.parallel8ProcessingTime,
-                      stats.parallel8LoadTime,
-                      stats.parallel12ProcessingTime,
-                      stats.parallel12LoadTime);
-    };
-
-    // We need this to pass into the jsonExtractor. It helps it being generic.
-    std::vector<std::string> columns = {
-        "flight_id", "seat", "user_id", "customer_name", 
-        "status", "payment_method", "reservation_time", "price"
-    };
-    
-    // TimerTrigger - processes random chunks (7000-21000 lines) every 5 seconds
-    auto timer_trigger = std::make_shared<TimerTrigger>(15000);
-    timer_trigger->setCallback([&]()
-    {
-        DataFrame<std::string> df = extractor.extractRandomChunk(file_path, columns, 7000, 21000);
-        processFullPipeline("Timer", df); 
-    });
-
-    // RequestTrigger - processes fixed 15000-line chunks
-    auto request_trigger = std::make_shared<RequestTrigger>();
-    request_trigger->setCallback([&]()
-    {
-        DataFrame<std::string> df = extractor.extractChunk(file_path, columns, 15000);
-        processFullPipeline("Request", df); 
-    });
-
-    // Start triggers
-    timer_trigger->start();
-    request_trigger->start();
-
-    // Simulate random requests
-    std::random_device rd;
-    std::mt19937 gen(rd());
-    std::uniform_int_distribution<> dist(2, 5);
-
-    for (int i = 0; i < 3; ++i)
-    {
-        std::this_thread::sleep_for(std::chrono::seconds(dist(gen)));
-        request_trigger->trigger();
-    }
-
-    // Run for 30 seconds
-    std::this_thread::sleep_for(std::chrono::seconds(30));
-    timer_trigger->stop();
-    request_trigger->stop();
-
-    // Final summary
-    std::cout << "\n=== FINAL SUMMARY ===\n";
-    std::cout << "Total executions: " << results.allRuns.size() << "\n";
-
-    // Calculate totals instead of averages
-    long totalSeqProc = 0, totalSeqLoad = 0;
-    long totalPar4Proc = 0, totalPar4Load = 0;
-    long totalPar8Proc = 0, totalPar8Load = 0;
-    long totalPar12Proc = 0, totalPar12Load = 0;
-    size_t totalLines = 0;
-
-    for (const auto &run : results.allRuns)
-    {
-        totalSeqProc += run.sequentialProcessingTime;
-        totalSeqLoad += run.sequentialLoadTime;
-        totalPar4Proc += run.parallel4ProcessingTime;
-        totalPar4Load += run.parallel4LoadTime;
-        totalPar8Proc += run.parallel8ProcessingTime;
-        totalPar8Load += run.parallel8LoadTime;
-        totalPar12Proc += run.parallel12ProcessingTime;
-        totalPar12Load += run.parallel12LoadTime;
-        totalLines += run.linesProcessed;
-    }
-
-    std::cout << "\nTotal Times (ms):\n";
-    std::cout << "Sequential: Processing=" << totalSeqProc << " | Loading=" << totalSeqLoad << "\n";
-    std::cout << "Parallel 4: Processing=" << totalPar4Proc << " | Loading=" << totalPar4Load << "\n";
-    std::cout << "Parallel 8: Processing=" << totalPar8Proc << " | Loading=" << totalPar8Load << "\n";
-    std::cout << "Parallel 12: Processing=" << totalPar12Proc << " | Loading=" << totalPar12Load << "\n";
-    std::cout << "Total lines processed: " << totalLines << "\n";
-}
-
-int main()
-{
-    Test();
-    
-    return 0;
-}
\ No newline at end of file
diff --git a/src/run_clients.sh b/src/run_clients.sh
new file mode 100644
index 0000000..52a3d73
--- /dev/null
+++ b/src/run_clients.sh
@@ -0,0 +1,37 @@
+#!/bin/bash
+
+# Configs
+NUM_CLIENTS=10       
+EVENTS_PER_CLIENT=5  
+CLIENT_SCRIPT_DIR="../grpc"
+CLIENT_SCRIPT_NAME="client.py" 
+TMUX_SESSION_NAME="grpc_clients" 
+
+
+echo "Iniciando $NUM_CLIENTS clientes"
+echo "O servidor gRPC (./exes/server.exe) deve estar ativo para essa execução!"
+
+# Verifica se outra sessão tmux já existe
+tmux has-session -t "$TMUX_SESSION_NAME" 2>/dev/null
+
+if [ $? != 0 ]; then
+    echo "Criando nova sessão tmux: $TMUX_SESSION_NAME"
+    # Primeiro cliente
+    tmux new-session -s "$TMUX_SESSION_NAME" -d "cd '$CLIENT_SCRIPT_DIR' && python3 '$CLIENT_SCRIPT_NAME' 1 '$EVENTS_PER_CLIENT'; echo 'Cliente 1 finalizado.'; exec bash"
+    sleep 0.3 # Pequena pausa
+
+    # Outros clientes
+    for i in $(seq 2 $NUM_CLIENTS); do
+        echo "Criando janela tmux para Cliente GRPC #$i..."
+        tmux new-window -t "$TMUX_SESSION_NAME:$i" -n "Client-$i" "cd '$CLIENT_SCRIPT_DIR' && python3 '$CLIENT_SCRIPT_NAME' 1 '$EVENTS_PER_CLIENT'; echo 'Cliente $i finalizado.'; exec bash"
+        sleep 0.3 # Pequena pausa
+    done
+
+    echo "Clientes Iniciados '$TMUX_SESSION_NAME'."
+    echo "Para acessar os clientes, digite: tmux attach -t $TMUX_SESSION_NAME"
+    echo "Para alternar entre os clientes, digite: Ctrl+b, depois (n) para próxima ou (p) para anterior."
+    echo "Para fechar uma janela: Ctrl+d"
+else
+    echo "Sessão já existe"
+    echo "Para anexar a sessão existente: tmux attach -t $TMUX_SESSION_NAME"
+fi
\ No newline at end of file
diff --git a/src/server.cpp b/src/server.cpp
new file mode 100644
index 0000000..2914268
--- /dev/null
+++ b/src/server.cpp
@@ -0,0 +1,135 @@
+#include <grpcpp/grpcpp.h>
+#include "event.pb.h"
+#include "dataframe.hpp"
+#include "event.grpc.pb.h"
+#include "database.h"
+#include "extractor.hpp"
+#include "etl.cpp"
+#include <string>
+#include <atomic>
+#include <thread>
+#include <iomanip>  // Para std::put_time
+#include <ctime>    // Para std::localtime
+
+using grpc::Server;
+using grpc::ServerBuilder;
+using grpc::ServerContext;
+using grpc::Status;
+using events::Event;
+using events::Ack;
+using events::EventService;
+
+// Função auxiliar para formatar timestamp
+std::string formatTimestamp(int64_t timestamp) {
+    const time_t time = timestamp / 1000;
+    struct tm* timeinfo = std::localtime(&time);
+    char buffer[80];
+    strftime(buffer, sizeof(buffer), "%Y-%m-%d %H:%M:%S", timeinfo);
+    return buffer;
+}
+
+class EventServiceImpl final : public EventService::Service {
+public:
+    EventServiceImpl(const std::string& db_path) : 
+        db(db_path), 
+        extractor(),
+        first_run(true)  
+    {
+        std::cout << "Servidor inicializado. Aguardando eventos..." << std::endl;
+    }
+
+    Status SendEvent(ServerContext* /*context*/, const Event* request, Ack* reply) override {
+        try {
+            // Validação básica dos dados
+            if (request->flight_id().empty() || 
+                request->seat().empty() || 
+                request->user_id().empty() ||
+                request->customer_name().empty()) {
+                throw std::runtime_error("Dados obrigatórios não fornecidos");
+            }
+
+            // Validação do status
+            const std::string status = request->status();
+            if (status != "pending" && status != "confirmed" && status != "cancelled") {
+                throw std::runtime_error("Status inválido");
+            }
+
+            // Validação do timestamp
+            if (request->timestamp() <= 0) {
+                throw std::runtime_error("Timestamp inválido");
+            }
+
+            // Log dos dados recebidos
+            std::cout << "\n=== NOVO EVENTO RECEBIDO ===" << std::endl;
+            std::cout << "Flight ID: " << request->flight_id() << std::endl;
+            std::cout << "Seat: " << request->seat() << std::endl;
+            std::cout << "User ID: " << request->user_id() << std::endl;
+            std::cout << "Customer: " << request->customer_name() << std::endl;
+            std::cout << "Status: " << status << std::endl;
+            std::cout << "Payment Method: " << request->payment_method() << std::endl;
+            std::cout << "Reservation Time: " << request->reservation_time() << std::endl;
+            std::cout << "Price: " << request->price() << std::endl;
+            std::cout << "Timestamp: " << formatTimestamp(request->timestamp()) 
+                    << " (" << request->timestamp() << ")" << std::endl;
+
+            // Converter o evento para DataFrame
+            DataFrame<std::string> df = extractor.extractFromGrpcEvent(request);
+            
+            // Configuração do processamento
+            TestResults::RunStats stats;
+            bool current_first_run = first_run.exchange(false);
+            
+            std::cout << "Iniciando processamento paralelo com " 
+                    << std::thread::hardware_concurrency() << " threads..." << std::endl;
+            
+            processParallelChunk(
+                getOptimalThreadCount(df.numRows()),
+                db,                                 
+                "grpc_stream",                      
+                df,
+                stats,
+                current_first_run                   
+            );
+            
+            std::cout << "Processamento concluído com sucesso" << std::endl;
+            
+            reply->set_message("Evento processado com sucesso");
+            
+            return Status::OK;
+        } catch (const std::exception& e) {
+            std::cerr << "ERRO NO PROCESSAMENTO: " << e.what() << std::endl;
+            reply->set_message("Cadastramento inválido: " + std::string(e.what()));
+            return Status(grpc::INVALID_ARGUMENT, "Cadastramento inválido");
+        }
+    }
+
+private:
+    DataBase db; 
+    Extractor extractor;
+    std::atomic<bool> first_run;
+    
+    unsigned int getOptimalThreadCount(size_t workload_size) {
+        const unsigned int hw_threads = std::thread::hardware_concurrency();
+        const unsigned int max_threads = (hw_threads == 0) ? 4 : hw_threads;
+        
+        if (workload_size < 50) return 1;
+        // if (workload_size < 5000) return std::min(4u, max_threads);
+        return max_threads;
+    }
+};
+
+void RunServer(const std::string& server_address, const std::string& db_path) {
+    EventServiceImpl service(db_path);
+    ServerBuilder builder;
+    builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());
+    builder.RegisterService(&service);
+    std::unique_ptr<Server> server(builder.BuildAndStart());
+    std::cout << "Servidor rodando em " << server_address << std::endl;
+    server->Wait();
+}
+
+int main() {
+    std::cout << "Iniciando servidor gRPC..." << std::endl;
+    RunServer("localhost:50051", "../databases/Database.db");
+    return 0;
+}
\ No newline at end of file
diff --git a/src/sqlite3.o b/src/sqlite3.o
deleted file mode 100644
index 374aaa4..0000000
Binary files a/src/sqlite3.o and /dev/null differ
